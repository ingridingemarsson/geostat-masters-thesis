{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from quantnn.qrnn import QRNN\n",
    "from quantnn.models.pytorch.logging import TensorBoardLogger\n",
    "\n",
    "import sys\n",
    "sys.path.append('../visualize')\n",
    "from sample_plots import plotRandomSample\n",
    "sys.path.append('../src')\n",
    "from load_data import GOESRETRIEVALSDataset, RandomLog, Mask, RandomCrop, Standardize, ToTensor\n",
    "from models.FirstGenericNet import Net \n",
    "net_name = 'FirstGenericNet' \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "channels = list(range(8,17))\n",
    "channels.remove(12)\n",
    "\n",
    "fillvalue = -1\n",
    "\n",
    "n_epochs = 20\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "quantiles = [0.25, 0.5, 0.75] #[0.01, 0.05, 0.15, 0.25, 0.35, 0.45, 0.5, 0.55, 0.65, 0.75, 0.85, 0.95, 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS TO DATA\n",
    "path_to_data = '../dataset/data/dataset-test/'\n",
    "path_to_save_model = '../results/saved_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_data = path_to_data + 'train/npy_files'\n",
    "path_to_stats = os.path.join(Path(path_to_train_data).parent, Path('stats.npy'))\n",
    "\n",
    "path_to_val_data = path_to_data + 'validation/npy_files'\n",
    "\n",
    "path_to_test_data = path_to_data + 'test/npy_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData(channels, BATCH_SIZE, path_to_data, path_to_stats):\n",
    "    dataset = GOESRETRIEVALSDataset(\n",
    "        path_to_data = path_to_data,\n",
    "        channels = channels, \n",
    "        transform = transforms.Compose([\n",
    "            #RandomLog(),\n",
    "            Mask(), \n",
    "            RandomCrop(128),\n",
    "            Standardize(path_to_data, path_to_stats, channels),\n",
    "            ToTensor()])\n",
    "    )\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return(dataset, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_dataloader = importData(channels, BATCH_SIZE, path_to_train_data, path_to_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset, val_dataloader = importData(channels, BATCH_SIZE, path_to_val_data, path_to_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT RANDOM SAMPLE\n",
    "plotRandomSample(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotRandomSample(val_dataset, c=[2,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(len(quantiles), len(channels))\n",
    "qrnn_model = QRNN(quantiles=quantiles, model=net)\n",
    "optimizer = SGD(net.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_dataloader\n",
    "validation_data = val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory = None\n",
    "logger = TensorBoardLogger(n_epochs, log_directory=log_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = CosineAnnealingLR(optimizer, n_epochs, 0.001)\n",
    "qrnn_model.train(training_data=training_data,\n",
    "              validation_data=validation_data,\n",
    "              keys=(\"box\", \"label\"),\n",
    "              n_epochs=n_epochs,\n",
    "              optimizer=optimizer,\n",
    "              scheduler=scheduler,\n",
    "              mask=fillvalue,\n",
    "              device=device,\n",
    "              logger=logger);\n",
    "scheduler = CosineAnnealingLR(optimizer, n_epochs, 0.0001)\n",
    "qrnn_model.train(training_data=training_data,\n",
    "              validation_data=validation_data,\n",
    "              keys=(\"box\", \"label\"),\n",
    "              n_epochs=n_epochs,\n",
    "              optimizer=optimizer,\n",
    "              scheduler=scheduler,\n",
    "              mask=fillvalue,\n",
    "              device=device,\n",
    "              logger=logger);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL\n",
    "#qrnn_model.save(path_to_save_model+'qrnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotRandomSample(val_dataset, qrnn=qrnn_model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_num=int(len(quantiles)/2)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for batch_index, batch in enumerate(val_dataloader):\n",
    "\n",
    "        y_true += [batch['label'].detach().numpy()]\n",
    "        \n",
    "        X = batch['box'].to(device).detach()\n",
    "        y_pred += [net(X)[:,quantile_num].cpu().detach().numpy()]\n",
    "\n",
    "y_true = np.concatenate(y_true, axis=0)\n",
    "y_pred = np.concatenate(y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.logspace(-2, 2, 81)\n",
    "indices = y_true >= 0.0\n",
    "\n",
    "\n",
    "freqs, _, _ = np.histogram2d(y_true[indices], y_pred[indices], bins=bins)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colors import Normalize\n",
    "#norm = Normalize(0, 400)\n",
    "\n",
    "f, axs = plt.subplots(figsize=(5, 6))\n",
    "\n",
    "ax = axs\n",
    "p = ax.pcolormesh(bins, bins, freqs.T,\n",
    "                  #norm=norm,  \n",
    "                  cmap=plt.get_cmap('magma'))\n",
    "ax.set_xlim([1e-2, 1e2])\n",
    "ax.set_ylim([1e-2, 1e2])\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Reference rain rate [mm / h]\")\n",
    "ax.set_ylabel(\"Predicted rain rate [mm / h]\")\n",
    "#ax.set_title(\"(a) Title\", loc=\"left\")\n",
    "ax.plot(bins, bins, c=\"grey\", ls=\"--\")\n",
    "f.colorbar(p, ax=ax, orientation=\"horizontal\", label=\"Surface precipitation [mm / h]\")\n",
    "ax.set_aspect(1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Non zero rain to all rain ratio (true): ', np.sum(y_true[indices]!=0.)/len(y_true[indices]))\n",
    "print('Non zero rain to all rain ratio (pred): ', np.sum(y_pred[indices]!=0.)/len(y_pred[indices]))\n",
    "\n",
    "TP = np.sum(y_pred[indices][(y_true[indices]!=0.)]!=0.)\n",
    "FN = np.sum(y_pred[indices][(y_true[indices]!=0.)]==0.)\n",
    "FP = np.sum(y_pred[indices][(y_true[indices]==0.)]!=0.)\n",
    "TN = np.sum(y_pred[indices][(y_true[indices]==0.)]==0.)\n",
    "\n",
    "TPR = TP/(TP+FN)\n",
    "print(TPR)\n",
    "FPR = FP/(FP+TN)\n",
    "print(FPR)\n",
    "\n",
    "ACC = (TP+TN)/(TP+FN+FP+TN)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_true[indices]))\n",
    "print(len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(train_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
