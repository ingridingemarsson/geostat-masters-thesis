{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "drawn-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ingrid/anaconda3/envs/geostat/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729062494/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ', device)\n",
    "\n",
    "from quantnn.qrnn import QRNN\n",
    "from quantnn.models.pytorch import BatchedDataset\n",
    "from quantnn.models.pytorch.logging import TensorBoardLogger\n",
    "\n",
    "from models.singles_fc import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "entitled-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "channels = [8, 13]\n",
    "fillvalue = -1\n",
    "\n",
    "n_epochs = 20\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "quantiles = np.linspace(0.01, 0.99, 99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "simple-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = 'dataset/data/dataset-singles/'\n",
    "X_train = np.load(path_to_data+'train/X_singles_dataset.npy')\n",
    "y_train = np.load(path_to_data+'train/y_singles_dataset.npy')\n",
    "X_val = np.load(path_to_data+'validation/X_singles_dataset.npy')\n",
    "y_val = np.load(path_to_data+'validation/y_singles_dataset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aware-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = 100000\n",
    "X_train = X_train[:subs].astype(np.float32)\n",
    "y_train = y_train[:subs].astype(np.float32)\n",
    "X_val = X_val[:subs].astype(np.float32)\n",
    "y_val = y_val[:subs].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hired-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardize(X, path_to_data):\n",
    "    stats = np.load(path_to_data+'train/X_singles_stats.npy')\n",
    "    return (X-stats[0,:])/stats[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "classified-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Standardize(X_train, path_to_data).astype(np.float32)\n",
    "X_val = Standardize(X_val, path_to_data).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minute-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fc = Net(len(quantiles), len(channels))\n",
    "qrnn_fc = QRNN(quantiles=quantiles, model=model_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "identified-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = BatchedDataset((X_train, y_train), 32)\n",
    "validation_data = BatchedDataset((X_val, y_val), 32)\n",
    "optimizer = SGD(model_fc.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "local-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory = None\n",
    "logger = TensorBoardLogger(n_epochs, log_directory=log_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "regular-register",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 20: train. loss = 0.1098, val. loss = 0.0445, lr. = 0.1000, time = 10.892674 s\n",
      "Epoch  2 / 20: train. loss = 0.1079, val. loss = 0.0453, lr. = 0.0978, time = 11.344881 s\n",
      "Batch 2499 / 3125: train. loss = 0.1075\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-abefb9991e6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCosineAnnealingLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m qrnn_fc.train(training_data=training_data,\n\u001b[0m\u001b[1;32m      4\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Git/quantnn/quantnn/qrnn.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data, validation_data, batch_size, optimizer, scheduler, n_epochs, adversarial_training, device, mask, logger, keys)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[1;32m    165\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQuantileLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         return self.model.train(training_data,\n\u001b[0m\u001b[1;32m    167\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                                 \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Git/quantnn/quantnn/models/pytorch/common.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data, validation_data, loss, optimizer, scheduler, n_epochs, adversarial_training, batch_size, device, logger, keys)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geostat/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geostat/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "scheduler = CosineAnnealingLR(optimizer, n_epochs, 0.01)\n",
    "qrnn_fc.train(training_data=training_data,\n",
    "              validation_data=validation_data,\n",
    "              n_epochs=n_epochs,\n",
    "              optimizer=optimizer,\n",
    "              scheduler=scheduler,\n",
    "              mask=-1,\n",
    "              device=device,\n",
    "              logger=logger);\n",
    "\n",
    "n_epochs = 20\n",
    "scheduler = CosineAnnealingLR(optimizer, n_epochs, 0.001)\n",
    "qrnn_fc.train(training_data=training_data,\n",
    "              validation_data=validation_data,\n",
    "              n_epochs=n_epochs,\n",
    "              optimizer=optimizer,\n",
    "              scheduler=scheduler,\n",
    "              mask=-1,\n",
    "              device=device,\n",
    "              logger=logger);\n",
    "\n",
    "n_epochs = 40\n",
    "scheduler = CosineAnnealingLR(optimizer, n_epochs, 0.0001)\n",
    "qrnn_fc.train(training_data=training_data,\n",
    "              validation_data=validation_data,\n",
    "              n_epochs=n_epochs,\n",
    "              optimizer=optimizer,\n",
    "              scheduler=scheduler,\n",
    "              mask=-1,\n",
    "              device=device,\n",
    "              logger=logger);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "validation_data = BatchedDataset((X_val, y_val), 32)\n",
    "\n",
    "y_true = []\n",
    "y_pred_fc = []\n",
    "for x, y in validation_data:\n",
    "  y_true += [y.detach().numpy()]\n",
    "  y_pred_fc += [qrnn_fc.posterior_mean(x=x).cpu().detach().numpy()]\n",
    "y_true = np.concatenate(y_true, axis=0)\n",
    "y_pred_fc = np.concatenate(y_pred_fc, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.logspace(-2, 2, 41)\n",
    "indices = y_true >= 0.0\n",
    "freqs_fc, _, _ = np.histogram2d(y_true[indices], y_pred_fc[indices], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "#norm = Normalize(0, 400)\n",
    "indices = y_val >= 0.0\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 9))\n",
    "\n",
    "\n",
    "p = ax.pcolormesh(bins, bins, freqs_fc.T, \n",
    "              #norm=norm\n",
    "             )\n",
    "ax.set_xlim([1e-2, 1e2])\n",
    "ax.set_ylim([1e-2, 1e2])\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Reference rain rate [mm / h]\")\n",
    "ax.set_ylabel(\"Predicted rain rate [mm / h]\")\n",
    "ax.set_title(\"(a) Fully-connected\", loc=\"left\")\n",
    "ax.plot(bins, bins, c=\"grey\", ls=\"--\")\n",
    "f.colorbar(p, ax=ax, orientation=\"horizontal\", label=\"Surface precipitation [mm / h]\")\n",
    "ax.set_aspect(1.0)\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
