device:  cuda
Batch 99 / 5251: train. loss = 0.0742Batch 199 / 5251: train. loss = 0.0737Batch 299 / 5251: train. loss = 0.0734Batch 399 / 5251: train. loss = 0.0731Batch 499 / 5251: train. loss = 0.0730Batch 599 / 5251: train. loss = 0.0729Batch 699 / 5251: train. loss = 0.0728Batch 799 / 5251: train. loss = 0.0727Batch 899 / 5251: train. loss = 0.0727Batch 999 / 5251: train. loss = 0.0725Batch 1099 / 5251: train. loss = 0.0725Batch 1199 / 5251: train. loss = 0.0726Batch 1299 / 5251: train. loss = 0.0726Batch 1399 / 5251: train. loss = 0.0726Batch 1499 / 5251: train. loss = 0.0725Batch 1599 / 5251: train. loss = 0.0725Batch 1699 / 5251: train. loss = 0.0725Batch 1799 / 5251: train. loss = 0.0725Batch 1899 / 5251: train. loss = 0.0725Batch 1999 / 5251: train. loss = 0.0724Batch 2099 / 5251: train. loss = 0.0724Batch 2199 / 5251: train. loss = 0.0723Batch 2299 / 5251: train. loss = 0.0723Batch 2399 / 5251: train. loss = 0.0722Batch 2499 / 5251: train. loss = 0.0721Batch 2599 / 5251: train. loss = 0.0720Batch 2699 / 5251: train. loss = 0.0719Batch 2799 / 5251: train. loss = 0.0718Batch 2899 / 5251: train. loss = 0.0718Batch 2999 / 5251: train. loss = 0.0716Batch 3099 / 5251: train. loss = 0.0716Batch 3199 / 5251: train. loss = 0.0715Batch 3299 / 5251: train. loss = 0.0714Batch 3399 / 5251: train. loss = 0.0713Batch 3499 / 5251: train. loss = 0.0713Batch 3599 / 5251: train. loss = 0.0712Batch 3699 / 5251: train. loss = 0.0711Batch 3799 / 5251: train. loss = 0.0710Batch 3899 / 5251: train. loss = 0.0710Batch 3999 / 5251: train. loss = 0.0709Batch 4099 / 5251: train. loss = 0.0709Batch 4199 / 5251: train. loss = 0.0708Batch 4299 / 5251: train. loss = 0.0708Batch 4399 / 5251: train. loss = 0.0707Batch 4499 / 5251: train. loss = 0.0707Batch 4599 / 5251: train. loss = 0.0706Batch 4699 / 5251: train. loss = 0.0705Batch 4799 / 5251: train. loss = 0.0705Batch 4899 / 5251: train. loss = 0.0705Batch 4999 / 5251: train. loss = 0.0704Batch 5099 / 5251: train. loss = 0.0704Batch 5199 / 5251: train. loss = 0.0703Epoch  1 / 10: train. loss = 0.0703, val. loss = 0.0746, lr. = 0.1000, time = 33.863545 s
Batch 99 / 5251: train. loss = 0.0684Batch 199 / 5251: train. loss = 0.0685Batch 299 / 5251: train. loss = 0.0681Batch 399 / 5251: train. loss = 0.0682Batch 499 / 5251: train. loss = 0.0682Batch 599 / 5251: train. loss = 0.0682Batch 699 / 5251: train. loss = 0.0681Batch 799 / 5251: train. loss = 0.0680Batch 899 / 5251: train. loss = 0.0680Batch 999 / 5251: train. loss = 0.0680Batch 1099 / 5251: train. loss = 0.0681Batch 1199 / 5251: train. loss = 0.0680Batch 1299 / 5251: train. loss = 0.0681Batch 1399 / 5251: train. loss = 0.0681Batch 1499 / 5251: train. loss = 0.0681Batch 1599 / 5251: train. loss = 0.0681Batch 1699 / 5251: train. loss = 0.0681Batch 1799 / 5251: train. loss = 0.0681Batch 1899 / 5251: train. loss = 0.0681Batch 1999 / 5251: train. loss = 0.0681Batch 2099 / 5251: train. loss = 0.0681Batch 2199 / 5251: train. loss = 0.0681Batch 2299 / 5251: train. loss = 0.0681Batch 2399 / 5251: train. loss = 0.0681Batch 2499 / 5251: train. loss = 0.0681Batch 2599 / 5251: train. loss = 0.0681Batch 2699 / 5251: train. loss = 0.0681Batch 2799 / 5251: train. loss = 0.0681Batch 2899 / 5251: train. loss = 0.0681Batch 2999 / 5251: train. loss = 0.0681Batch 3099 / 5251: train. loss = 0.0681Batch 3199 / 5251: train. loss = 0.0681Batch 3299 / 5251: train. loss = 0.0681Batch 3399 / 5251: train. loss = 0.0681Batch 3499 / 5251: train. loss = 0.0681Batch 3599 / 5251: train. loss = 0.0681Batch 3699 / 5251: train. loss = 0.0681Batch 3799 / 5251: train. loss = 0.0681Batch 3899 / 5251: train. loss = 0.0681Batch 3999 / 5251: train. loss = 0.0681Batch 4099 / 5251: train. loss = 0.0682Batch 4199 / 5251: train. loss = 0.0682Batch 4299 / 5251: train. loss = 0.0682Batch 4399 / 5251: train. loss = 0.0682Batch 4499 / 5251: train. loss = 0.0682Batch 4599 / 5251: train. loss = 0.0682Batch 4699 / 5251: train. loss = 0.0682Batch 4799 / 5251: train. loss = 0.0682Batch 4899 / 5251: train. loss = 0.0682Batch 4999 / 5251: train. loss = 0.0681Batch 5099 / 5251: train. loss = 0.0681Batch 5199 / 5251: train. loss = 0.0681Epoch  2 / 10: train. loss = 0.0681, val. loss = 0.0744, lr. = 0.0978, time = 33.60293 s
Batch 99 / 5251: train. loss = 0.0677Batch 199 / 5251: train. loss = 0.0678Batch 299 / 5251: train. loss = 0.0680Batch 399 / 5251: train. loss = 0.0679Batch 499 / 5251: train. loss = 0.0678Batch 599 / 5251: train. loss = 0.0677Batch 699 / 5251: train. loss = 0.0680Batch 799 / 5251: train. loss = 0.0681Batch 899 / 5251: train. loss = 0.0681Batch 999 / 5251: train. loss = 0.0681Batch 1099 / 5251: train. loss = 0.0681Batch 1199 / 5251: train. loss = 0.0681Batch 1299 / 5251: train. loss = 0.0681Batch 1399 / 5251: train. loss = 0.0682Batch 1499 / 5251: train. loss = 0.0681Batch 1599 / 5251: train. loss = 0.0682Batch 1699 / 5251: train. loss = 0.0681Batch 1799 / 5251: train. loss = 0.0681Batch 1899 / 5251: train. loss = 0.0682Batch 1999 / 5251: train. loss = 0.0682Batch 2099 / 5251: train. loss = 0.0682Batch 2199 / 5251: train. loss = 0.0682Batch 2299 / 5251: train. loss = 0.0681Batch 2399 / 5251: train. loss = 0.0681Batch 2499 / 5251: train. loss = 0.0681Batch 2599 / 5251: train. loss = 0.0681Batch 2699 / 5251: train. loss = 0.0681Batch 2799 / 5251: train. loss = 0.0681Batch 2899 / 5251: train. loss = 0.0681Batch 2999 / 5251: train. loss = 0.0681Batch 3099 / 5251: train. loss = 0.0681Batch 3199 / 5251: train. loss = 0.0681Batch 3299 / 5251: train. loss = 0.0681Batch 3399 / 5251: train. loss = 0.0681Batch 3499 / 5251: train. loss = 0.0681Batch 3599 / 5251: train. loss = 0.0681Batch 3699 / 5251: train. loss = 0.0681Batch 3799 / 5251: train. loss = 0.0681Batch 3899 / 5251: train. loss = 0.0680Batch 3999 / 5251: train. loss = 0.0680Batch 4099 / 5251: train. loss = 0.0680Batch 4199 / 5251: train. loss = 0.0680Batch 4299 / 5251: train. loss = 0.0680Batch 4399 / 5251: train. loss = 0.0680Batch 4499 / 5251: train. loss = 0.0680Batch 4599 / 5251: train. loss = 0.0680Batch 4699 / 5251: train. loss = 0.0680Batch 4799 / 5251: train. loss = 0.0680Batch 4899 / 5251: train. loss = 0.0680Batch 4999 / 5251: train. loss = 0.0680Batch 5099 / 5251: train. loss = 0.0680Batch 5199 / 5251: train. loss = 0.0680Epoch  3 / 10: train. loss = 0.0680, val. loss = 0.0743, lr. = 0.0914, time = 33.486797 s
Batch 99 / 5251: train. loss = 0.0685Batch 199 / 5251: train. loss = 0.0686Batch 299 / 5251: train. loss = 0.0684Batch 399 / 5251: train. loss = 0.0684Batch 499 / 5251: train. loss = 0.0684Batch 599 / 5251: train. loss = 0.0685Batch 699 / 5251: train. loss = 0.0684Batch 799 / 5251: train. loss = 0.0684Batch 899 / 5251: train. loss = 0.0684Batch 999 / 5251: train. loss = 0.0684Batch 1099 / 5251: train. loss = 0.0684Batch 1199 / 5251: train. loss = 0.0684Batch 1299 / 5251: train. loss = 0.0683Batch 1399 / 5251: train. loss = 0.0683Batch 1499 / 5251: train. loss = 0.0683Batch 1599 / 5251: train. loss = 0.0683Batch 1699 / 5251: train. loss = 0.0683Batch 1799 / 5251: train. loss = 0.0683Batch 1899 / 5251: train. loss = 0.0683Batch 1999 / 5251: train. loss = 0.0682Batch 2099 / 5251: train. loss = 0.0682Batch 2199 / 5251: train. loss = 0.0682Batch 2299 / 5251: train. loss = 0.0682Batch 2399 / 5251: train. loss = 0.0681Batch 2499 / 5251: train. loss = 0.0681Batch 2599 / 5251: train. loss = 0.0681Batch 2699 / 5251: train. loss = 0.0681Batch 2799 / 5251: train. loss = 0.0681Batch 2899 / 5251: train. loss = 0.0681Batch 2999 / 5251: train. loss = 0.0681Batch 3099 / 5251: train. loss = 0.0681Batch 3199 / 5251: train. loss = 0.0680Batch 3299 / 5251: train. loss = 0.0680Batch 3399 / 5251: train. loss = 0.0680Batch 3499 / 5251: train. loss = 0.0680Batch 3599 / 5251: train. loss = 0.0680Batch 3699 / 5251: train. loss = 0.0680Batch 3799 / 5251: train. loss = 0.0680Batch 3899 / 5251: train. loss = 0.0680Batch 3999 / 5251: train. loss = 0.0680Batch 4099 / 5251: train. loss = 0.0680Batch 4199 / 5251: train. loss = 0.0680Batch 4299 / 5251: train. loss = 0.0680Batch 4399 / 5251: train. loss = 0.0680Batch 4499 / 5251: train. loss = 0.0679Batch 4599 / 5251: train. loss = 0.0679Batch 4699 / 5251: train. loss = 0.0680Batch 4799 / 5251: train. loss = 0.0680Batch 4899 / 5251: train. loss = 0.0680Batch 4999 / 5251: train. loss = 0.0679Batch 5099 / 5251: train. loss = 0.0680Batch 5199 / 5251: train. loss = 0.0679Epoch  4 / 10: train. loss = 0.0679, val. loss = 0.0742, lr. = 0.0815, time = 33.476481 s
Batch 99 / 5251: train. loss = 0.0675Batch 199 / 5251: train. loss = 0.0675Batch 299 / 5251: train. loss = 0.0678Batch 399 / 5251: train. loss = 0.0679Batch 499 / 5251: train. loss = 0.0679Batch 599 / 5251: train. loss = 0.0679Batch 699 / 5251: train. loss = 0.0680Batch 799 / 5251: train. loss = 0.0680Batch 899 / 5251: train. loss = 0.0680Batch 999 / 5251: train. loss = 0.0679Batch 1099 / 5251: train. loss = 0.0679Batch 1199 / 5251: train. loss = 0.0680Batch 1299 / 5251: train. loss = 0.0680Batch 1399 / 5251: train. loss = 0.0679Batch 1499 / 5251: train. loss = 0.0679Batch 1599 / 5251: train. loss = 0.0679Batch 1699 / 5251: train. loss = 0.0679Batch 1799 / 5251: train. loss = 0.0679Batch 1899 / 5251: train. loss = 0.0679Batch 1999 / 5251: train. loss = 0.0679Batch 2099 / 5251: train. loss = 0.0679Batch 2199 / 5251: train. loss = 0.0679Batch 2299 / 5251: train. loss = 0.0679Batch 2399 / 5251: train. loss = 0.0679Batch 2499 / 5251: train. loss = 0.0679Batch 2599 / 5251: train. loss = 0.0679Batch 2699 / 5251: train. loss = 0.0678Batch 2799 / 5251: train. loss = 0.0679Batch 2899 / 5251: train. loss = 0.0678Batch 2999 / 5251: train. loss = 0.0679Batch 3099 / 5251: train. loss = 0.0678Batch 3199 / 5251: train. loss = 0.0678Batch 3299 / 5251: train. loss = 0.0679Batch 3399 / 5251: train. loss = 0.0679Batch 3499 / 5251: train. loss = 0.0679Batch 3599 / 5251: train. loss = 0.0679Batch 3699 / 5251: train. loss = 0.0679Batch 3799 / 5251: train. loss = 0.0679Batch 3899 / 5251: train. loss = 0.0679Batch 3999 / 5251: train. loss = 0.0679Batch 4099 / 5251: train. loss = 0.0679Batch 4199 / 5251: train. loss = 0.0679Batch 4299 / 5251: train. loss = 0.0679Batch 4399 / 5251: train. loss = 0.0679Batch 4499 / 5251: train. loss = 0.0679Batch 4599 / 5251: train. loss = 0.0679Batch 4699 / 5251: train. loss = 0.0679Batch 4799 / 5251: train. loss = 0.0679Batch 4899 / 5251: train. loss = 0.0679Batch 4999 / 5251: train. loss = 0.0679Batch 5099 / 5251: train. loss = 0.0679Batch 5199 / 5251: train. loss = 0.0679Epoch  5 / 10: train. loss = 0.0679, val. loss = 0.0742, lr. = 0.0689, time = 33.573119 s
Batch 99 / 5251: train. loss = 0.0678Batch 199 / 5251: train. loss = 0.0680Batch 299 / 5251: train. loss = 0.0679Batch 399 / 5251: train. loss = 0.0680Batch 499 / 5251: train. loss = 0.0680Batch 599 / 5251: train. loss = 0.0679Batch 699 / 5251: train. loss = 0.0679Batch 799 / 5251: train. loss = 0.0678Batch 899 / 5251: train. loss = 0.0679Batch 999 / 5251: train. loss = 0.0678Batch 1099 / 5251: train. loss = 0.0678Batch 1199 / 5251: train. loss = 0.0678Batch 1299 / 5251: train. loss = 0.0678Batch 1399 / 5251: train. loss = 0.0677Batch 1499 / 5251: train. loss = 0.0677Batch 1599 / 5251: train. loss = 0.0677Batch 1699 / 5251: train. loss = 0.0678Batch 1799 / 5251: train. loss = 0.0678Batch 1899 / 5251: train. loss = 0.0678Batch 1999 / 5251: train. loss = 0.0678Batch 2099 / 5251: train. loss = 0.0678Batch 2199 / 5251: train. loss = 0.0678Batch 2299 / 5251: train. loss = 0.0678Batch 2399 / 5251: train. loss = 0.0679Batch 2499 / 5251: train. loss = 0.0679Batch 2599 / 5251: train. loss = 0.0679Batch 2699 / 5251: train. loss = 0.0679Batch 2799 / 5251: train. loss = 0.0679Batch 2899 / 5251: train. loss = 0.0679Batch 2999 / 5251: train. loss = 0.0679Batch 3099 / 5251: train. loss = 0.0679Batch 3199 / 5251: train. loss = 0.0679Batch 3299 / 5251: train. loss = 0.0679Batch 3399 / 5251: train. loss = 0.0679Batch 3499 / 5251: train. loss = 0.0679Batch 3599 / 5251: train. loss = 0.0679Batch 3699 / 5251: train. loss = 0.0679Batch 3799 / 5251: train. loss = 0.0678Batch 3899 / 5251: train. loss = 0.0678Batch 3999 / 5251: train. loss = 0.0678Batch 4099 / 5251: train. loss = 0.0678Batch 4199 / 5251: train. loss = 0.0679Batch 4299 / 5251: train. loss = 0.0679Batch 4399 / 5251: train. loss = 0.0679Batch 4499 / 5251: train. loss = 0.0679Batch 4599 / 5251: train. loss = 0.0679Batch 4699 / 5251: train. loss = 0.0679Batch 4799 / 5251: train. loss = 0.0679Batch 4899 / 5251: train. loss = 0.0679Batch 4999 / 5251: train. loss = 0.0679Batch 5099 / 5251: train. loss = 0.0679Batch 5199 / 5251: train. loss = 0.0678Epoch  6 / 10: train. loss = 0.0679, val. loss = 0.0741, lr. = 0.0550, time = 33.45644 s
Batch 99 / 5251: train. loss = 0.0672Batch 199 / 5251: train. loss = 0.0673Batch 299 / 5251: train. loss = 0.0675Batch 399 / 5251: train. loss = 0.0677Batch 499 / 5251: train. loss = 0.0676Batch 599 / 5251: train. loss = 0.0678Batch 699 / 5251: train. loss = 0.0677Batch 799 / 5251: train. loss = 0.0677Batch 899 / 5251: train. loss = 0.0677Batch 999 / 5251: train. loss = 0.0677Batch 1099 / 5251: train. loss = 0.0677Batch 1199 / 5251: train. loss = 0.0677Batch 1299 / 5251: train. loss = 0.0677Batch 1399 / 5251: train. loss = 0.0677Batch 1499 / 5251: train. loss = 0.0677Batch 1599 / 5251: train. loss = 0.0678Batch 1699 / 5251: train. loss = 0.0678Batch 1799 / 5251: train. loss = 0.0678Batch 1899 / 5251: train. loss = 0.0678Batch 1999 / 5251: train. loss = 0.0678Batch 2099 / 5251: train. loss = 0.0678Batch 2199 / 5251: train. loss = 0.0678Batch 2299 / 5251: train. loss = 0.0678Batch 2399 / 5251: train. loss = 0.0678Batch 2499 / 5251: train. loss = 0.0678Batch 2599 / 5251: train. loss = 0.0678Batch 2699 / 5251: train. loss = 0.0678Batch 2799 / 5251: train. loss = 0.0678Batch 2899 / 5251: train. loss = 0.0678Batch 2999 / 5251: train. loss = 0.0679Batch 3099 / 5251: train. loss = 0.0679Batch 3199 / 5251: train. loss = 0.0679Batch 3299 / 5251: train. loss = 0.0679Batch 3399 / 5251: train. loss = 0.0678Batch 3499 / 5251: train. loss = 0.0679Batch 3599 / 5251: train. loss = 0.0679Batch 3699 / 5251: train. loss = 0.0679Batch 3799 / 5251: train. loss = 0.0678Batch 3899 / 5251: train. loss = 0.0678Batch 3999 / 5251: train. loss = 0.0679Batch 4099 / 5251: train. loss = 0.0679Batch 4199 / 5251: train. loss = 0.0679Batch 4299 / 5251: train. loss = 0.0678Batch 4399 / 5251: train. loss = 0.0678Batch 4499 / 5251: train. loss = 0.0679Batch 4599 / 5251: train. loss = 0.0679Batch 4699 / 5251: train. loss = 0.0679Batch 4799 / 5251: train. loss = 0.0679Batch 4899 / 5251: train. loss = 0.0679Batch 4999 / 5251: train. loss = 0.0678Batch 5099 / 5251: train. loss = 0.0678Batch 5199 / 5251: train. loss = 0.0678Epoch  7 / 10: train. loss = 0.0678, val. loss = 0.0741, lr. = 0.0411, time = 33.820748 s
Batch 99 / 5251: train. loss = 0.0679Batch 199 / 5251: train. loss = 0.0678Batch 299 / 5251: train. loss = 0.0678Batch 399 / 5251: train. loss = 0.0679Batch 499 / 5251: train. loss = 0.0678Batch 599 / 5251: train. loss = 0.0678Batch 699 / 5251: train. loss = 0.0679Batch 799 / 5251: train. loss = 0.0680Batch 899 / 5251: train. loss = 0.0680Batch 999 / 5251: train. loss = 0.0679Batch 1099 / 5251: train. loss = 0.0679Batch 1199 / 5251: train. loss = 0.0679Batch 1299 / 5251: train. loss = 0.0680Batch 1399 / 5251: train. loss = 0.0680Batch 1499 / 5251: train. loss = 0.0680Batch 1599 / 5251: train. loss = 0.0680Batch 1699 / 5251: train. loss = 0.0679Batch 1799 / 5251: train. loss = 0.0679Batch 1899 / 5251: train. loss = 0.0679Batch 1999 / 5251: train. loss = 0.0679Batch 2099 / 5251: train. loss = 0.0679Batch 2199 / 5251: train. loss = 0.0679Batch 2299 / 5251: train. loss = 0.0679Batch 2399 / 5251: train. loss = 0.0679Batch 2499 / 5251: train. loss = 0.0679Batch 2599 / 5251: train. loss = 0.0679Batch 2699 / 5251: train. loss = 0.0679Batch 2799 / 5251: train. loss = 0.0679Batch 2899 / 5251: train. loss = 0.0679Batch 2999 / 5251: train. loss = 0.0679Batch 3099 / 5251: train. loss = 0.0679Batch 3199 / 5251: train. loss = 0.0678Batch 3299 / 5251: train. loss = 0.0678Batch 3399 / 5251: train. loss = 0.0678Batch 3499 / 5251: train. loss = 0.0678Batch 3599 / 5251: train. loss = 0.0678Batch 3699 / 5251: train. loss = 0.0678Batch 3799 / 5251: train. loss = 0.0678Batch 3899 / 5251: train. loss = 0.0678Batch 3999 / 5251: train. loss = 0.0678Batch 4099 / 5251: train. loss = 0.0678Batch 4199 / 5251: train. loss = 0.0678Batch 4299 / 5251: train. loss = 0.0678Batch 4399 / 5251: train. loss = 0.0678Batch 4499 / 5251: train. loss = 0.0678Batch 4599 / 5251: train. loss = 0.0678Batch 4699 / 5251: train. loss = 0.0678Batch 4799 / 5251: train. loss = 0.0678Batch 4899 / 5251: train. loss = 0.0678Batch 4999 / 5251: train. loss = 0.0678Batch 5099 / 5251: train. loss = 0.0678Batch 5199 / 5251: train. loss = 0.0678Epoch  8 / 10: train. loss = 0.0678, val. loss = 0.0741, lr. = 0.0285, time = 33.414099 s
Batch 99 / 5251: train. loss = 0.0676Batch 199 / 5251: train. loss = 0.0676Batch 299 / 5251: train. loss = 0.0677Batch 399 / 5251: train. loss = 0.0676Batch 499 / 5251: train. loss = 0.0676Batch 599 / 5251: train. loss = 0.0677Batch 699 / 5251: train. loss = 0.0678Batch 799 / 5251: train. loss = 0.0678Batch 899 / 5251: train. loss = 0.0679Batch 999 / 5251: train. loss = 0.0679Batch 1099 / 5251: train. loss = 0.0678Batch 1199 / 5251: train. loss = 0.0679Batch 1299 / 5251: train. loss = 0.0678Batch 1399 / 5251: train. loss = 0.0678Batch 1499 / 5251: train. loss = 0.0678Batch 1599 / 5251: train. loss = 0.0678Batch 1699 / 5251: train. loss = 0.0678Batch 1799 / 5251: train. loss = 0.0678Batch 1899 / 5251: train. loss = 0.0678Batch 1999 / 5251: train. loss = 0.0678Batch 2099 / 5251: train. loss = 0.0678Batch 2199 / 5251: train. loss = 0.0678Batch 2299 / 5251: train. loss = 0.0678Batch 2399 / 5251: train. loss = 0.0678Batch 2499 / 5251: train. loss = 0.0678Batch 2599 / 5251: train. loss = 0.0678Batch 2699 / 5251: train. loss = 0.0678Batch 2799 / 5251: train. loss = 0.0678Batch 2899 / 5251: train. loss = 0.0678Batch 2999 / 5251: train. loss = 0.0678Batch 3099 / 5251: train. loss = 0.0678Batch 3199 / 5251: train. loss = 0.0678Batch 3299 / 5251: train. loss = 0.0678Batch 3399 / 5251: train. loss = 0.0678Batch 3499 / 5251: train. loss = 0.0678Batch 3599 / 5251: train. loss = 0.0678Batch 3699 / 5251: train. loss = 0.0678Batch 3799 / 5251: train. loss = 0.0678Batch 3899 / 5251: train. loss = 0.0678Batch 3999 / 5251: train. loss = 0.0678Batch 4099 / 5251: train. loss = 0.0678Batch 4199 / 5251: train. loss = 0.0678Batch 4299 / 5251: train. loss = 0.0678Batch 4399 / 5251: train. loss = 0.0678Batch 4499 / 5251: train. loss = 0.0678Batch 4599 / 5251: train. loss = 0.0678Batch 4699 / 5251: train. loss = 0.0678Batch 4799 / 5251: train. loss = 0.0678Batch 4899 / 5251: train. loss = 0.0678Batch 4999 / 5251: train. loss = 0.0678Batch 5099 / 5251: train. loss = 0.0678Batch 5199 / 5251: train. loss = 0.0678Epoch  9 / 10: train. loss = 0.0678, val. loss = 0.0741, lr. = 0.0186, time = 33.678084 s
Batch 99 / 5251: train. loss = 0.0684Batch 199 / 5251: train. loss = 0.0681Batch 299 / 5251: train. loss = 0.0680Batch 399 / 5251: train. loss = 0.0678Batch 499 / 5251: train. loss = 0.0678Batch 599 / 5251: train. loss = 0.0678Batch 699 / 5251: train. loss = 0.0678Batch 799 / 5251: train. loss = 0.0678Batch 899 / 5251: train. loss = 0.0677Batch 999 / 5251: train. loss = 0.0677Batch 1099 / 5251: train. loss = 0.0677Batch 1199 / 5251: train. loss = 0.0677Batch 1299 / 5251: train. loss = 0.0677Batch 1399 / 5251: train. loss = 0.0677Batch 1499 / 5251: train. loss = 0.0678Batch 1599 / 5251: train. loss = 0.0678Batch 1699 / 5251: train. loss = 0.0678Batch 1799 / 5251: train. loss = 0.0678Batch 1899 / 5251: train. loss = 0.0678Batch 1999 / 5251: train. loss = 0.0678Batch 2099 / 5251: train. loss = 0.0678Batch 2199 / 5251: train. loss = 0.0679Batch 2299 / 5251: train. loss = 0.0679Batch 2399 / 5251: train. loss = 0.0679Batch 2499 / 5251: train. loss = 0.0678Batch 2599 / 5251: train. loss = 0.0678Batch 2699 / 5251: train. loss = 0.0678Batch 2799 / 5251: train. loss = 0.0678Batch 2899 / 5251: train. loss = 0.0679Batch 2999 / 5251: train. loss = 0.0678Batch 3099 / 5251: train. loss = 0.0679Batch 3199 / 5251: train. loss = 0.0679Batch 3299 / 5251: train. loss = 0.0679Batch 3399 / 5251: train. loss = 0.0678Batch 3499 / 5251: train. loss = 0.0678Batch 3599 / 5251: train. loss = 0.0678Batch 3699 / 5251: train. loss = 0.0678Batch 3799 / 5251: train. loss = 0.0678Batch 3899 / 5251: train. loss = 0.0678Batch 3999 / 5251: train. loss = 0.0678Batch 4099 / 5251: train. loss = 0.0678Batch 4199 / 5251: train. loss = 0.0678Batch 4299 / 5251: train. loss = 0.0678Batch 4399 / 5251: train. loss = 0.0678Batch 4499 / 5251: train. loss = 0.0678Batch 4599 / 5251: train. loss = 0.0678Batch 4699 / 5251: train. loss = 0.0678Batch 4799 / 5251: train. loss = 0.0678Batch 4899 / 5251: train. loss = 0.0678Batch 4999 / 5251: train. loss = 0.0678Batch 5099 / 5251: train. loss = 0.0678Batch 5199 / 5251: train. loss = 0.0678Epoch 10 / 10: train. loss = 0.0678, val. loss = 0.0741, lr. = 0.0122, time = 33.562765 s
Batch 99 / 5251: train. loss = 0.0677Batch 199 / 5251: train. loss = 0.0678Batch 299 / 5251: train. loss = 0.0679Batch 399 / 5251: train. loss = 0.0677Batch 499 / 5251: train. loss = 0.0677Batch 599 / 5251: train. loss = 0.0677Batch 699 / 5251: train. loss = 0.0676Batch 799 / 5251: train. loss = 0.0677Batch 899 / 5251: train. loss = 0.0677Batch 999 / 5251: train. loss = 0.0678Batch 1099 / 5251: train. loss = 0.0678Batch 1199 / 5251: train. loss = 0.0678Batch 1299 / 5251: train. loss = 0.0678Batch 1399 / 5251: train. loss = 0.0678Batch 1499 / 5251: train. loss = 0.0678Batch 1599 / 5251: train. loss = 0.0679Batch 1699 / 5251: train. loss = 0.0679Batch 1799 / 5251: train. loss = 0.0679Batch 1899 / 5251: train. loss = 0.0679Batch 1999 / 5251: train. loss = 0.0679Batch 2099 / 5251: train. loss = 0.0678Batch 2199 / 5251: train. loss = 0.0678Batch 2299 / 5251: train. loss = 0.0678Batch 2399 / 5251: train. loss = 0.0678Batch 2499 / 5251: train. loss = 0.0678Batch 2599 / 5251: train. loss = 0.0678Batch 2699 / 5251: train. loss = 0.0678Batch 2799 / 5251: train. loss = 0.0678Batch 2899 / 5251: train. loss = 0.0678Batch 2999 / 5251: train. loss = 0.0678Batch 3099 / 5251: train. loss = 0.0678Batch 3199 / 5251: train. loss = 0.0678Batch 3299 / 5251: train. loss = 0.0678Batch 3399 / 5251: train. loss = 0.0678Batch 3499 / 5251: train. loss = 0.0678Batch 3599 / 5251: train. loss = 0.0678Batch 3699 / 5251: train. loss = 0.0678Batch 3799 / 5251: train. loss = 0.0678Batch 3899 / 5251: train. loss = 0.0678Batch 3999 / 5251: train. loss = 0.0678Batch 4099 / 5251: train. loss = 0.0678Batch 4199 / 5251: train. loss = 0.0678Batch 4299 / 5251: train. loss = 0.0678Batch 4399 / 5251: train. loss = 0.0678Batch 4499 / 5251: train. loss = 0.0678Batch 4599 / 5251: train. loss = 0.0678Batch 4699 / 5251: train. loss = 0.0678Batch 4799 / 5251: train. loss = 0.0678Batch 4899 / 5251: train. loss = 0.0678Batch 4999 / 5251: train. loss = 0.0678Batch 5099 / 5251: train. loss = 0.0678Batch 5199 / 5251: train. loss = 0.0678Epoch  1 / 20: train. loss = 0.0678, val. loss = 0.0740, lr. = 0.1000, time = 33.863208 s
Batch 99 / 5251: train. loss = 0.0675Batch 199 / 5251: train. loss = 0.0675Batch 299 / 5251: train. loss = 0.0674Batch 399 / 5251: train. loss = 0.0674Batch 499 / 5251: train. loss = 0.0674Batch 599 / 5251: train. loss = 0.0675Batch 699 / 5251: train. loss = 0.0676Batch 799 / 5251: train. loss = 0.0677Batch 899 / 5251: train. loss = 0.0677Batch 999 / 5251: train. loss = 0.0678Batch 1099 / 5251: train. loss = 0.0679Batch 1199 / 5251: train. loss = 0.0678Batch 1299 / 5251: train. loss = 0.0678Batch 1399 / 5251: train. loss = 0.0678Batch 1499 / 5251: train. loss = 0.0678Batch 1599 / 5251: train. loss = 0.0678Batch 1699 / 5251: train. loss = 0.0677Batch 1799 / 5251: train. loss = 0.0677Batch 1899 / 5251: train. loss = 0.0678Batch 1999 / 5251: train. loss = 0.0678Batch 2099 / 5251: train. loss = 0.0678Batch 2199 / 5251: train. loss = 0.0678Batch 2299 / 5251: train. loss = 0.0678Batch 2399 / 5251: train. loss = 0.0678Batch 2499 / 5251: train. loss = 0.0678Batch 2599 / 5251: train. loss = 0.0678Batch 2699 / 5251: train. loss = 0.0678Batch 2799 / 5251: train. loss = 0.0678Batch 2899 / 5251: train. loss = 0.0678Batch 2999 / 5251: train. loss = 0.0678Batch 3099 / 5251: train. loss = 0.0678Batch 3199 / 5251: train. loss = 0.0678Batch 3299 / 5251: train. loss = 0.0678Batch 3399 / 5251: train. loss = 0.0678Batch 3499 / 5251: train. loss = 0.0677Batch 3599 / 5251: train. loss = 0.0677Batch 3699 / 5251: train. loss = 0.0678Batch 3799 / 5251: train. loss = 0.0677Batch 3899 / 5251: train. loss = 0.0678Batch 3999 / 5251: train. loss = 0.0678Batch 4099 / 5251: train. loss = 0.0678Batch 4199 / 5251: train. loss = 0.0678Batch 4299 / 5251: train. loss = 0.0678Batch 4399 / 5251: train. loss = 0.0677Batch 4499 / 5251: train. loss = 0.0677Batch 4599 / 5251: train. loss = 0.0677Batch 4699 / 5251: train. loss = 0.0677Batch 4799 / 5251: train. loss = 0.0677Batch 4899 / 5251: train. loss = 0.0677Batch 4999 / 5251: train. loss = 0.0677Batch 5099 / 5251: train. loss = 0.0677Batch 5199 / 5251: train. loss = 0.0677Epoch  2 / 20: train. loss = 0.0677, val. loss = 0.0740, lr. = 0.0994, time = 33.92056 s
Batch 99 / 5251: train. loss = 0.0684Batch 199 / 5251: train. loss = 0.0684Batch 299 / 5251: train. loss = 0.0681Batch 399 / 5251: train. loss = 0.0679Batch 499 / 5251: train. loss = 0.0678Batch 599 / 5251: train. loss = 0.0678Batch 699 / 5251: train. loss = 0.0678Batch 799 / 5251: train. loss = 0.0678Batch 899 / 5251: train. loss = 0.0677Batch 999 / 5251: train. loss = 0.0677Batch 1099 / 5251: train. loss = 0.0677Batch 1199 / 5251: train. loss = 0.0677Batch 1299 / 5251: train. loss = 0.0677Batch 1399 / 5251: train. loss = 0.0677Batch 1499 / 5251: train. loss = 0.0677Batch 1599 / 5251: train. loss = 0.0677Batch 1699 / 5251: train. loss = 0.0677Batch 1799 / 5251: train. loss = 0.0677Batch 1899 / 5251: train. loss = 0.0677Batch 1999 / 5251: train. loss = 0.0677Batch 2099 / 5251: train. loss = 0.0677Batch 2199 / 5251: train. loss = 0.0677Batch 2299 / 5251: train. loss = 0.0677Batch 2399 / 5251: train. loss = 0.0677Batch 2499 / 5251: train. loss = 0.0677Batch 2599 / 5251: train. loss = 0.0677Batch 2699 / 5251: train. loss = 0.0677Batch 2799 / 5251: train. loss = 0.0677Batch 2899 / 5251: train. loss = 0.0677Batch 2999 / 5251: train. loss = 0.0677Batch 3099 / 5251: train. loss = 0.0677Batch 3199 / 5251: train. loss = 0.0677Batch 3299 / 5251: train. loss = 0.0677Batch 3399 / 5251: train. loss = 0.0677Batch 3499 / 5251: train. loss = 0.0676Batch 3599 / 5251: train. loss = 0.0677Batch 3699 / 5251: train. loss = 0.0677Batch 3799 / 5251: train. loss = 0.0677Batch 3899 / 5251: train. loss = 0.0677Batch 3999 / 5251: train. loss = 0.0677Batch 4099 / 5251: train. loss = 0.0677Batch 4199 / 5251: train. loss = 0.0677Batch 4299 / 5251: train. loss = 0.0677Batch 4399 / 5251: train. loss = 0.0677Batch 4499 / 5251: train. loss = 0.0677Batch 4599 / 5251: train. loss = 0.0677Batch 4699 / 5251: train. loss = 0.0677Batch 4799 / 5251: train. loss = 0.0677Batch 4899 / 5251: train. loss = 0.0677Batch 4999 / 5251: train. loss = 0.0677Batch 5099 / 5251: train. loss = 0.0677Batch 5199 / 5251: train. loss = 0.0677Epoch  3 / 20: train. loss = 0.0677, val. loss = 0.0740, lr. = 0.0976, time = 33.851462 s
Batch 99 / 5251: train. loss = 0.0678Batch 199 / 5251: train. loss = 0.0676Batch 299 / 5251: train. loss = 0.0677Batch 399 / 5251: train. loss = 0.0677Batch 499 / 5251: train. loss = 0.0677Batch 599 / 5251: train. loss = 0.0675Batch 699 / 5251: train. loss = 0.0677Batch 799 / 5251: train. loss = 0.0677Batch 899 / 5251: train. loss = 0.0678Batch 999 / 5251: train. loss = 0.0677Batch 1099 / 5251: train. loss = 0.0677Batch 1199 / 5251: train. loss = 0.0677Batch 1299 / 5251: train. loss = 0.0677Batch 1399 / 5251: train. loss = 0.0677Batch 1499 / 5251: train. loss = 0.0677Batch 1599 / 5251: train. loss = 0.0677Batch 1699 / 5251: train. loss = 0.0677Batch 1799 / 5251: train. loss = 0.0677Batch 1899 / 5251: train. loss = 0.0677Batch 1999 / 5251: train. loss = 0.0677Batch 2099 / 5251: train. loss = 0.0677Batch 2199 / 5251: train. loss = 0.0677Batch 2299 / 5251: train. loss = 0.0677Batch 2399 / 5251: train. loss = 0.0677Batch 2499 / 5251: train. loss = 0.0677Batch 2599 / 5251: train. loss = 0.0676Batch 2699 / 5251: train. loss = 0.0676Batch 2799 / 5251: train. loss = 0.0676Batch 2899 / 5251: train. loss = 0.0676Batch 2999 / 5251: train. loss = 0.0676Batch 3099 / 5251: train. loss = 0.0676Batch 3199 / 5251: train. loss = 0.0677Batch 3299 / 5251: train. loss = 0.0676Batch 3399 / 5251: train. loss = 0.0676Batch 3499 / 5251: train. loss = 0.0676Batch 3599 / 5251: train. loss = 0.0676Batch 3699 / 5251: train. loss = 0.0676Batch 3799 / 5251: train. loss = 0.0676Batch 3899 / 5251: train. loss = 0.0676Batch 3999 / 5251: train. loss = 0.0676Batch 4099 / 5251: train. loss = 0.0676Batch 4199 / 5251: train. loss = 0.0676Batch 4299 / 5251: train. loss = 0.0676Batch 4399 / 5251: train. loss = 0.0676Batch 4499 / 5251: train. loss = 0.0676Batch 4599 / 5251: train. loss = 0.0676Batch 4699 / 5251: train. loss = 0.0676Batch 4799 / 5251: train. loss = 0.0676Batch 4899 / 5251: train. loss = 0.0676Batch 4999 / 5251: train. loss = 0.0676Batch 5099 / 5251: train. loss = 0.0676Batch 5199 / 5251: train. loss = 0.0677Epoch  4 / 20: train. loss = 0.0677, val. loss = 0.0739, lr. = 0.0946, time = 33.78169 s
Batch 99 / 5251: train. loss = 0.0677Batch 199 / 5251: train. loss = 0.0679Batch 299 / 5251: train. loss = 0.0676Batch 399 / 5251: train. loss = 0.0677Batch 499 / 5251: train. loss = 0.0676Batch 599 / 5251: train. loss = 0.0674Batch 699 / 5251: train. loss = 0.0675Batch 799 / 5251: train. loss = 0.0674Batch 899 / 5251: train. loss = 0.0675Batch 999 / 5251: train. loss = 0.0675Batch 1099 / 5251: train. loss = 0.0675Batch 1199 / 5251: train. loss = 0.0676Batch 1299 / 5251: train. loss = 0.0676Batch 1399 / 5251: train. loss = 0.0676Batch 1499 / 5251: train. loss = 0.0677Batch 1599 / 5251: train. loss = 0.0677Batch 1699 / 5251: train. loss = 0.0676Batch 1799 / 5251: train. loss = 0.0676Batch 1899 / 5251: train. loss = 0.0676Batch 1999 / 5251: train. loss = 0.0676Batch 2099 / 5251: train. loss = 0.0676Batch 2199 / 5251: train. loss = 0.0676Batch 2299 / 5251: train. loss = 0.0676Batch 2399 / 5251: train. loss = 0.0676Batch 2499 / 5251: train. loss = 0.0676Batch 2599 / 5251: train. loss = 0.0676Batch 2699 / 5251: train. loss = 0.0676Batch 2799 / 5251: train. loss = 0.0676Batch 2899 / 5251: train. loss = 0.0676Batch 2999 / 5251: train. loss = 0.0677Batch 3099 / 5251: train. loss = 0.0677Batch 3199 / 5251: train. loss = 0.0677Batch 3299 / 5251: train. loss = 0.0677Batch 3399 / 5251: train. loss = 0.0677Batch 3499 / 5251: train. loss = 0.0677Batch 3599 / 5251: train. loss = 0.0677Batch 3699 / 5251: train. loss = 0.0677Batch 3799 / 5251: train. loss = 0.0676Batch 3899 / 5251: train. loss = 0.0676Batch 3999 / 5251: train. loss = 0.0676Batch 4099 / 5251: train. loss = 0.0676Batch 4199 / 5251: train. loss = 0.0676Batch 4299 / 5251: train. loss = 0.0676Batch 4399 / 5251: train. loss = 0.0676Batch 4499 / 5251: train. loss = 0.0676Batch 4599 / 5251: train. loss = 0.0676Batch 4699 / 5251: train. loss = 0.0677Batch 4799 / 5251: train. loss = 0.0677Batch 4899 / 5251: train. loss = 0.0676Batch 4999 / 5251: train. loss = 0.0676Batch 5099 / 5251: train. loss = 0.0676Batch 5199 / 5251: train. loss = 0.0676Epoch  5 / 20: train. loss = 0.0676, val. loss = 0.0739, lr. = 0.0905, time = 33.690325 s
Batch 99 / 5251: train. loss = 0.0678Batch 199 / 5251: train. loss = 0.0678Batch 299 / 5251: train. loss = 0.0676Batch 399 / 5251: train. loss = 0.0676Batch 499 / 5251: train. loss = 0.0677Batch 599 / 5251: train. loss = 0.0677Batch 699 / 5251: train. loss = 0.0677Batch 799 / 5251: train. loss = 0.0679Batch 899 / 5251: train. loss = 0.0678Batch 999 / 5251: train. loss = 0.0678Batch 1099 / 5251: train. loss = 0.0678Batch 1199 / 5251: train. loss = 0.0678Batch 1299 / 5251: train. loss = 0.0678Batch 1399 / 5251: train. loss = 0.0677Batch 1499 / 5251: train. loss = 0.0677Batch 1599 / 5251: train. loss = 0.0677Batch 1699 / 5251: train. loss = 0.0677Batch 1799 / 5251: train. loss = 0.0677Batch 1899 / 5251: train. loss = 0.0677Batch 1999 / 5251: train. loss = 0.0677Batch 2099 / 5251: train. loss = 0.0677Batch 2199 / 5251: train. loss = 0.0677Batch 2299 / 5251: train. loss = 0.0677Batch 2399 / 5251: train. loss = 0.0677Batch 2499 / 5251: train. loss = 0.0677Batch 2599 / 5251: train. loss = 0.0677Batch 2699 / 5251: train. loss = 0.0677Batch 2799 / 5251: train. loss = 0.0677Batch 2899 / 5251: train. loss = 0.0676Batch 2999 / 5251: train. loss = 0.0677Batch 3099 / 5251: train. loss = 0.0676Batch 3199 / 5251: train. loss = 0.0676Batch 3299 / 5251: train. loss = 0.0676Batch 3399 / 5251: train. loss = 0.0676Batch 3499 / 5251: train. loss = 0.0676Batch 3599 / 5251: train. loss = 0.0677Batch 3699 / 5251: train. loss = 0.0677Batch 3799 / 5251: train. loss = 0.0677Batch 3899 / 5251: train. loss = 0.0677Batch 3999 / 5251: train. loss = 0.0677Batch 4099 / 5251: train. loss = 0.0677Batch 4199 / 5251: train. loss = 0.0676Batch 4299 / 5251: train. loss = 0.0676Batch 4399 / 5251: train. loss = 0.0676Batch 4499 / 5251: train. loss = 0.0676Batch 4599 / 5251: train. loss = 0.0676Batch 4699 / 5251: train. loss = 0.0676Batch 4799 / 5251: train. loss = 0.0676Batch 4899 / 5251: train. loss = 0.0676Batch 4999 / 5251: train. loss = 0.0676Batch 5099 / 5251: train. loss = 0.0676Batch 5199 / 5251: train. loss = 0.0676Epoch  6 / 20: train. loss = 0.0676, val. loss = 0.0739, lr. = 0.0855, time = 33.62747 s
Batch 99 / 5251: train. loss = 0.0680Batch 199 / 5251: train. loss = 0.0673Batch 299 / 5251: train. loss = 0.0674Batch 399 / 5251: train. loss = 0.0674Batch 499 / 5251: train. loss = 0.0676Batch 599 / 5251: train. loss = 0.0676Batch 699 / 5251: train. loss = 0.0676Batch 799 / 5251: train. loss = 0.0676Batch 899 / 5251: train. loss = 0.0676Batch 999 / 5251: train. loss = 0.0677Batch 1099 / 5251: train. loss = 0.0676Batch 1199 / 5251: train. loss = 0.0676Batch 1299 / 5251: train. loss = 0.0677Batch 1399 / 5251: train. loss = 0.0676Batch 1499 / 5251: train. loss = 0.0676Batch 1599 / 5251: train. loss = 0.0676Batch 1699 / 5251: train. loss = 0.0676Batch 1799 / 5251: train. loss = 0.0676Batch 1899 / 5251: train. loss = 0.0676Batch 1999 / 5251: train. loss = 0.0676Batch 2099 / 5251: train. loss = 0.0676Batch 2199 / 5251: train. loss = 0.0676Batch 2299 / 5251: train. loss = 0.0676Batch 2399 / 5251: train. loss = 0.0676Batch 2499 / 5251: train. loss = 0.0676Batch 2599 / 5251: train. loss = 0.0676Batch 2699 / 5251: train. loss = 0.0676Batch 2799 / 5251: train. loss = 0.0676Batch 2899 / 5251: train. loss = 0.0676Batch 2999 / 5251: train. loss = 0.0676Batch 3099 / 5251: train. loss = 0.0676Batch 3199 / 5251: train. loss = 0.0676Batch 3299 / 5251: train. loss = 0.0676Batch 3399 / 5251: train. loss = 0.0676Batch 3499 / 5251: train. loss = 0.0676Batch 3599 / 5251: train. loss = 0.0676Batch 3699 / 5251: train. loss = 0.0676Batch 3799 / 5251: train. loss = 0.0676Batch 3899 / 5251: train. loss = 0.0676Batch 3999 / 5251: train. loss = 0.0676Batch 4099 / 5251: train. loss = 0.0676Batch 4199 / 5251: train. loss = 0.0676Batch 4299 / 5251: train. loss = 0.0676Batch 4399 / 5251: train. loss = 0.0676Batch 4499 / 5251: train. loss = 0.0676Batch 4599 / 5251: train. loss = 0.0676Batch 4699 / 5251: train. loss = 0.0676Batch 4799 / 5251: train. loss = 0.0676Batch 4899 / 5251: train. loss = 0.0676Batch 4999 / 5251: train. loss = 0.0676Batch 5099 / 5251: train. loss = 0.0676Batch 5199 / 5251: train. loss = 0.0676Epoch  7 / 20: train. loss = 0.0676, val. loss = 0.0739, lr. = 0.0796, time = 33.62688 s
Batch 99 / 5251: train. loss = 0.0671Batch 199 / 5251: train. loss = 0.0677Batch 299 / 5251: train. loss = 0.0677Batch 399 / 5251: train. loss = 0.0676Batch 499 / 5251: train. loss = 0.0675Batch 599 / 5251: train. loss = 0.0675Batch 699 / 5251: train. loss = 0.0675Batch 799 / 5251: train. loss = 0.0674Batch 899 / 5251: train. loss = 0.0675Batch 999 / 5251: train. loss = 0.0676Batch 1099 / 5251: train. loss = 0.0676Batch 1199 / 5251: train. loss = 0.0676Batch 1299 / 5251: train. loss = 0.0676Batch 1399 / 5251: train. loss = 0.0676Batch 1499 / 5251: train. loss = 0.0675Batch 1599 / 5251: train. loss = 0.0675Batch 1699 / 5251: train. loss = 0.0676Batch 1799 / 5251: train. loss = 0.0676Batch 1899 / 5251: train. loss = 0.0676Batch 1999 / 5251: train. loss = 0.0676Batch 2099 / 5251: train. loss = 0.0676Batch 2199 / 5251: train. loss = 0.0676Batch 2299 / 5251: train. loss = 0.0676Batch 2399 / 5251: train. loss = 0.0676Batch 2499 / 5251: train. loss = 0.0676Batch 2599 / 5251: train. loss = 0.0676Batch 2699 / 5251: train. loss = 0.0676Batch 2799 / 5251: train. loss = 0.0676Batch 2899 / 5251: train. loss = 0.0676Batch 2999 / 5251: train. loss = 0.0676Batch 3099 / 5251: train. loss = 0.0676Batch 3199 / 5251: train. loss = 0.0676Batch 3299 / 5251: train. loss = 0.0676Batch 3399 / 5251: train. loss = 0.0676Batch 3499 / 5251: train. loss = 0.0676Batch 3599 / 5251: train. loss = 0.0676Batch 3699 / 5251: train. loss = 0.0676Batch 3799 / 5251: train. loss = 0.0676Batch 3899 / 5251: train. loss = 0.0676Batch 3999 / 5251: train. loss = 0.0676Batch 4099 / 5251: train. loss = 0.0676Batch 4199 / 5251: train. loss = 0.0676Batch 4299 / 5251: train. loss = 0.0676Batch 4399 / 5251: train. loss = 0.0676Batch 4499 / 5251: train. loss = 0.0676Batch 4599 / 5251: train. loss = 0.0676Batch 4699 / 5251: train. loss = 0.0676Batch 4799 / 5251: train. loss = 0.0676Batch 4899 / 5251: train. loss = 0.0676Batch 4999 / 5251: train. loss = 0.0676Batch 5099 / 5251: train. loss = 0.0676Batch 5199 / 5251: train. loss = 0.0676Epoch  8 / 20: train. loss = 0.0676, val. loss = 0.0739, lr. = 0.0730, time = 33.694184 s
Batch 99 / 5251: train. loss = 0.0676Batch 199 / 5251: train. loss = 0.0672Batch 299 / 5251: train. loss = 0.0676Batch 399 / 5251: train. loss = 0.0673Batch 499 / 5251: train. loss = 0.0674Batch 599 / 5251: train. loss = 0.0674Batch 699 / 5251: train. loss = 0.0675Batch 799 / 5251: train. loss = 0.0675Batch 899 / 5251: train. loss = 0.0674Batch 999 / 5251: train. loss = 0.0674Batch 1099 / 5251: train. loss = 0.0674Batch 1199 / 5251: train. loss = 0.0675Batch 1299 / 5251: train. loss = 0.0675Batch 1399 / 5251: train. loss = 0.0675Batch 1499 / 5251: train. loss = 0.0675Batch 1599 / 5251: train. loss = 0.0674Batch 1699 / 5251: train. loss = 0.0675Batch 1799 / 5251: train. loss = 0.0675Batch 1899 / 5251: train. loss = 0.0675Batch 1999 / 5251: train. loss = 0.0675Batch 2099 / 5251: train. loss = 0.0675Batch 2199 / 5251: train. loss = 0.0675Batch 2299 / 5251: train. loss = 0.0675Batch 2399 / 5251: train. loss = 0.0675Batch 2499 / 5251: train. loss = 0.0675Batch 2599 / 5251: train. loss = 0.0675Batch 2699 / 5251: train. loss = 0.0675Batch 2799 / 5251: train. loss = 0.0675Batch 2899 / 5251: train. loss = 0.0675Batch 2999 / 5251: train. loss = 0.0675Batch 3099 / 5251: train. loss = 0.0675Batch 3199 / 5251: train. loss = 0.0676Batch 3299 / 5251: train. loss = 0.0676Batch 3399 / 5251: train. loss = 0.0676Batch 3499 / 5251: train. loss = 0.0676Batch 3599 / 5251: train. loss = 0.0676Batch 3699 / 5251: train. loss = 0.0676Batch 3799 / 5251: train. loss = 0.0676Batch 3899 / 5251: train. loss = 0.0676Batch 3999 / 5251: train. loss = 0.0676Batch 4099 / 5251: train. loss = 0.0676Batch 4199 / 5251: train. loss = 0.0676Batch 4299 / 5251: train. loss = 0.0676Batch 4399 / 5251: train. loss = 0.0676Batch 4499 / 5251: train. loss = 0.0676Batch 4599 / 5251: train. loss = 0.0676Batch 4699 / 5251: train. loss = 0.0676Batch 4799 / 5251: train. loss = 0.0676Batch 4899 / 5251: train. loss = 0.0676Batch 4999 / 5251: train. loss = 0.0676Batch 5099 / 5251: train. loss = 0.0676Batch 5199 / 5251: train. loss = 0.0676Epoch  9 / 20: train. loss = 0.0676, val. loss = 0.0739, lr. = 0.0658, time = 33.623865 s
Batch 99 / 5251: train. loss = 0.0680Batch 199 / 5251: train. loss = 0.0675Batch 299 / 5251: train. loss = 0.0674Batch 399 / 5251: train. loss = 0.0676Batch 499 / 5251: train. loss = 0.0676Batch 599 / 5251: train. loss = 0.0675Batch 699 / 5251: train. loss = 0.0676Batch 799 / 5251: train. loss = 0.0676Batch 899 / 5251: train. loss = 0.0677Batch 999 / 5251: train. loss = 0.0677Batch 1099 / 5251: train. loss = 0.0677Batch 1199 / 5251: train. loss = 0.0677Batch 1299 / 5251: train. loss = 0.0677Batch 1399 / 5251: train. loss = 0.0678Batch 1499 / 5251: train. loss = 0.0678Batch 1599 / 5251: train. loss = 0.0677Batch 1699 / 5251: train. loss = 0.0677Batch 1799 / 5251: train. loss = 0.0677Batch 1899 / 5251: train. loss = 0.0677Batch 1999 / 5251: train. loss = 0.0676Batch 2099 / 5251: train. loss = 0.0676Batch 2199 / 5251: train. loss = 0.0677Batch 2299 / 5251: train. loss = 0.0677Batch 2399 / 5251: train. loss = 0.0676Batch 2499 / 5251: train. loss = 0.0676Batch 2599 / 5251: train. loss = 0.0676Batch 2699 / 5251: train. loss = 0.0676Batch 2799 / 5251: train. loss = 0.0677Batch 2899 / 5251: train. loss = 0.0676Batch 2999 / 5251: train. loss = 0.0676Batch 3099 / 5251: train. loss = 0.0676Batch 3199 / 5251: train. loss = 0.0676Batch 3299 / 5251: train. loss = 0.0676Batch 3399 / 5251: train. loss = 0.0676Batch 3499 / 5251: train. loss = 0.0676Batch 3599 / 5251: train. loss = 0.0676Batch 3699 / 5251: train. loss = 0.0676Batch 3799 / 5251: train. loss = 0.0676Batch 3899 / 5251: train. loss = 0.0676Batch 3999 / 5251: train. loss = 0.0676Batch 4099 / 5251: train. loss = 0.0676Batch 4199 / 5251: train. loss = 0.0676Batch 4299 / 5251: train. loss = 0.0676Batch 4399 / 5251: train. loss = 0.0676Batch 4499 / 5251: train. loss = 0.0676Batch 4599 / 5251: train. loss = 0.0676Batch 4699 / 5251: train. loss = 0.0676Batch 4799 / 5251: train. loss = 0.0676Batch 4899 / 5251: train. loss = 0.0676Batch 4999 / 5251: train. loss = 0.0676Batch 5099 / 5251: train. loss = 0.0675Batch 5199 / 5251: train. loss = 0.0676Epoch 10 / 20: train. loss = 0.0676, val. loss = 0.0739, lr. = 0.0582, time = 33.814155 s
Batch 99 / 5251: train. loss = 0.0677Batch 199 / 5251: train. loss = 0.0679Batch 299 / 5251: train. loss = 0.0676Batch 399 / 5251: train. loss = 0.0676Batch 499 / 5251: train. loss = 0.0674Batch 599 / 5251: train. loss = 0.0674Batch 699 / 5251: train. loss = 0.0675Batch 799 / 5251: train. loss = 0.0677Batch 899 / 5251: train. loss = 0.0677Batch 999 / 5251: train. loss = 0.0677Batch 1099 / 5251: train. loss = 0.0677Batch 1199 / 5251: train. loss = 0.0677Batch 1299 / 5251: train. loss = 0.0677Batch 1399 / 5251: train. loss = 0.0677Batch 1499 / 5251: train. loss = 0.0677Batch 1599 / 5251: train. loss = 0.0678Batch 1699 / 5251: train. loss = 0.0678Batch 1799 / 5251: train. loss = 0.0678Batch 1899 / 5251: train. loss = 0.0678Batch 1999 / 5251: train. loss = 0.0678Batch 2099 / 5251: train. loss = 0.0677Batch 2199 / 5251: train. loss = 0.0677Batch 2299 / 5251: train. loss = 0.0677Batch 2399 / 5251: train. loss = 0.0677Batch 2499 / 5251: train. loss = 0.0677Batch 2599 / 5251: train. loss = 0.0676Batch 2699 / 5251: train. loss = 0.0676Batch 2799 / 5251: train. loss = 0.0676Batch 2899 / 5251: train. loss = 0.0676Batch 2999 / 5251: train. loss = 0.0676Batch 3099 / 5251: train. loss = 0.0676Batch 3199 / 5251: train. loss = 0.0676Batch 3299 / 5251: train. loss = 0.0675Batch 3399 / 5251: train. loss = 0.0675Batch 3499 / 5251: train. loss = 0.0675Batch 3599 / 5251: train. loss = 0.0675Batch 3699 / 5251: train. loss = 0.0675Batch 3799 / 5251: train. loss = 0.0675Batch 3899 / 5251: train. loss = 0.0675Batch 3999 / 5251: train. loss = 0.0675Batch 4099 / 5251: train. loss = 0.0675Batch 4199 / 5251: train. loss = 0.0675Batch 4299 / 5251: train. loss = 0.0675Batch 4399 / 5251: train. loss = 0.0675Batch 4499 / 5251: train. loss = 0.0676Batch 4599 / 5251: train. loss = 0.0676Batch 4699 / 5251: train. loss = 0.0676Batch 4799 / 5251: train. loss = 0.0676Batch 4899 / 5251: train. loss = 0.0676Batch 4999 / 5251: train. loss = 0.0676Batch 5099 / 5251: train. loss = 0.0676Batch 5199 / 5251: train. loss = 0.0676Epoch 11 / 20: train. loss = 0.0676, val. loss = 0.0739, lr. = 0.0505, time = 33.85764 s
Batch 99 / 5251: train. loss = 0.0675Batch 199 / 5251: train. loss = 0.0677Batch 299 / 5251: train. loss = 0.0677Batch 399 / 5251: train. loss = 0.0677Batch 499 / 5251: train. loss = 0.0677Batch 599 / 5251: train. loss = 0.0676Batch 699 / 5251: train. loss = 0.0677Batch 799 / 5251: train. loss = 0.0677Batch 899 / 5251: train. loss = 0.0677Batch 999 / 5251: train. loss = 0.0676Batch 1099 / 5251: train. loss = 0.0676Batch 1199 / 5251: train. loss = 0.0676Batch 1299 / 5251: train. loss = 0.0676Batch 1399 / 5251: train. loss = 0.0676Batch 1499 / 5251: train. loss = 0.0676Batch 1599 / 5251: train. loss = 0.0676Batch 1699 / 5251: train. loss = 0.0676Batch 1799 / 5251: train. loss = 0.0677Batch 1899 / 5251: train. loss = 0.0676Batch 1999 / 5251: train. loss = 0.0677Batch 2099 / 5251: train. loss = 0.0676Batch 2199 / 5251: train. loss = 0.0676Batch 2299 / 5251: train. loss = 0.0676Batch 2399 / 5251: train. loss = 0.0676Batch 2499 / 5251: train. loss = 0.0676Batch 2599 / 5251: train. loss = 0.0676Batch 2699 / 5251: train. loss = 0.0676Batch 2799 / 5251: train. loss = 0.0676Batch 2899 / 5251: train. loss = 0.0676Batch 2999 / 5251: train. loss = 0.0675Batch 3099 / 5251: train. loss = 0.0675Batch 3199 / 5251: train. loss = 0.0675Batch 3299 / 5251: train. loss = 0.0675Batch 3399 / 5251: train. loss = 0.0675Batch 3499 / 5251: train. loss = 0.0675Batch 3599 / 5251: train. loss = 0.0675Batch 3699 / 5251: train. loss = 0.0675Batch 3799 / 5251: train. loss = 0.0675Batch 3899 / 5251: train. loss = 0.0675Batch 3999 / 5251: train. loss = 0.0675Batch 4099 / 5251: train. loss = 0.0675Batch 4199 / 5251: train. loss = 0.0675Batch 4299 / 5251: train. loss = 0.0675Batch 4399 / 5251: train. loss = 0.0675Batch 4499 / 5251: train. loss = 0.0675Batch 4599 / 5251: train. loss = 0.0675Batch 4699 / 5251: train. loss = 0.0675Batch 4799 / 5251: train. loss = 0.0675Batch 4899 / 5251: train. loss = 0.0675Batch 4999 / 5251: train. loss = 0.0674Batch 5099 / 5251: train. loss = 0.0675Batch 5199 / 5251: train. loss = 0.0674Epoch 12 / 20: train. loss = 0.0674, val. loss = 0.0735, lr. = 0.0428, time = 33.563901 s
Batch 99 / 5251: train. loss = 0.0672Batch 199 / 5251: train. loss = 0.0670Batch 299 / 5251: train. loss = 0.0672Batch 399 / 5251: train. loss = 0.0673Batch 499 / 5251: train. loss = 0.0674Batch 599 / 5251: train. loss = 0.0673Batch 699 / 5251: train. loss = 0.0673Batch 799 / 5251: train. loss = 0.0673Batch 899 / 5251: train. loss = 0.0673Batch 999 / 5251: train. loss = 0.0674Batch 1099 / 5251: train. loss = 0.0674Batch 1199 / 5251: train. loss = 0.0673Batch 1299 / 5251: train. loss = 0.0673Batch 1399 / 5251: train. loss = 0.0674Batch 1499 / 5251: train. loss = 0.0673Batch 1599 / 5251: train. loss = 0.0673Batch 1699 / 5251: train. loss = 0.0673Batch 1799 / 5251: train. loss = 0.0673Batch 1899 / 5251: train. loss = 0.0673Batch 1999 / 5251: train. loss = 0.0673Batch 2099 / 5251: train. loss = 0.0673Batch 2199 / 5251: train. loss = 0.0673Batch 2299 / 5251: train. loss = 0.0674Batch 2399 / 5251: train. loss = 0.0673Batch 2499 / 5251: train. loss = 0.0673Batch 2599 / 5251: train. loss = 0.0673Batch 2699 / 5251: train. loss = 0.0674Batch 2799 / 5251: train. loss = 0.0673Batch 2899 / 5251: train. loss = 0.0673Batch 2999 / 5251: train. loss = 0.0673Batch 3099 / 5251: train. loss = 0.0673Batch 3199 / 5251: train. loss = 0.0673Batch 3299 / 5251: train. loss = 0.0673Batch 3399 / 5251: train. loss = 0.0673Batch 3499 / 5251: train. loss = 0.0673Batch 3599 / 5251: train. loss = 0.0673Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0673Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch 13 / 20: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.0352, time = 33.777992 s
Batch 99 / 5251: train. loss = 0.0671Batch 199 / 5251: train. loss = 0.0669Batch 299 / 5251: train. loss = 0.0670Batch 399 / 5251: train. loss = 0.0671Batch 499 / 5251: train. loss = 0.0673Batch 599 / 5251: train. loss = 0.0672Batch 699 / 5251: train. loss = 0.0673Batch 799 / 5251: train. loss = 0.0672Batch 899 / 5251: train. loss = 0.0673Batch 999 / 5251: train. loss = 0.0673Batch 1099 / 5251: train. loss = 0.0673Batch 1199 / 5251: train. loss = 0.0673Batch 1299 / 5251: train. loss = 0.0673Batch 1399 / 5251: train. loss = 0.0672Batch 1499 / 5251: train. loss = 0.0672Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0673Batch 2199 / 5251: train. loss = 0.0672Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0673Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0673Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0673Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0673Batch 4499 / 5251: train. loss = 0.0673Batch 4599 / 5251: train. loss = 0.0673Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch 14 / 20: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.0280, time = 33.684551 s
Batch 99 / 5251: train. loss = 0.0666Batch 199 / 5251: train. loss = 0.0670Batch 299 / 5251: train. loss = 0.0673Batch 399 / 5251: train. loss = 0.0673Batch 499 / 5251: train. loss = 0.0673Batch 599 / 5251: train. loss = 0.0674Batch 699 / 5251: train. loss = 0.0673Batch 799 / 5251: train. loss = 0.0674Batch 899 / 5251: train. loss = 0.0673Batch 999 / 5251: train. loss = 0.0673Batch 1099 / 5251: train. loss = 0.0674Batch 1199 / 5251: train. loss = 0.0673Batch 1299 / 5251: train. loss = 0.0674Batch 1399 / 5251: train. loss = 0.0674Batch 1499 / 5251: train. loss = 0.0674Batch 1599 / 5251: train. loss = 0.0673Batch 1699 / 5251: train. loss = 0.0674Batch 1799 / 5251: train. loss = 0.0674Batch 1899 / 5251: train. loss = 0.0673Batch 1999 / 5251: train. loss = 0.0673Batch 2099 / 5251: train. loss = 0.0673Batch 2199 / 5251: train. loss = 0.0673Batch 2299 / 5251: train. loss = 0.0673Batch 2399 / 5251: train. loss = 0.0673Batch 2499 / 5251: train. loss = 0.0673Batch 2599 / 5251: train. loss = 0.0673Batch 2699 / 5251: train. loss = 0.0673Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0673Batch 2999 / 5251: train. loss = 0.0673Batch 3099 / 5251: train. loss = 0.0673Batch 3199 / 5251: train. loss = 0.0673Batch 3299 / 5251: train. loss = 0.0673Batch 3399 / 5251: train. loss = 0.0673Batch 3499 / 5251: train. loss = 0.0673Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch 15 / 20: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.0214, time = 33.722714 s
Batch 99 / 5251: train. loss = 0.0671Batch 199 / 5251: train. loss = 0.0673Batch 299 / 5251: train. loss = 0.0674Batch 399 / 5251: train. loss = 0.0675Batch 499 / 5251: train. loss = 0.0675Batch 599 / 5251: train. loss = 0.0674Batch 699 / 5251: train. loss = 0.0672Batch 799 / 5251: train. loss = 0.0672Batch 899 / 5251: train. loss = 0.0672Batch 999 / 5251: train. loss = 0.0673Batch 1099 / 5251: train. loss = 0.0673Batch 1199 / 5251: train. loss = 0.0672Batch 1299 / 5251: train. loss = 0.0672Batch 1399 / 5251: train. loss = 0.0672Batch 1499 / 5251: train. loss = 0.0671Batch 1599 / 5251: train. loss = 0.0671Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0671Batch 1899 / 5251: train. loss = 0.0671Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0672Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch 16 / 20: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.0155, time = 33.681366 s
Batch 99 / 5251: train. loss = 0.0665Batch 199 / 5251: train. loss = 0.0668Batch 299 / 5251: train. loss = 0.0669Batch 399 / 5251: train. loss = 0.0669Batch 499 / 5251: train. loss = 0.0670Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0671Batch 799 / 5251: train. loss = 0.0672Batch 899 / 5251: train. loss = 0.0673Batch 999 / 5251: train. loss = 0.0672Batch 1099 / 5251: train. loss = 0.0673Batch 1199 / 5251: train. loss = 0.0673Batch 1299 / 5251: train. loss = 0.0673Batch 1399 / 5251: train. loss = 0.0673Batch 1499 / 5251: train. loss = 0.0673Batch 1599 / 5251: train. loss = 0.0673Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0673Batch 1899 / 5251: train. loss = 0.0673Batch 1999 / 5251: train. loss = 0.0673Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0672Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch 17 / 20: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.0105, time = 33.884917 s
Batch 99 / 5251: train. loss = 0.0674Batch 199 / 5251: train. loss = 0.0674Batch 299 / 5251: train. loss = 0.0673Batch 399 / 5251: train. loss = 0.0673Batch 499 / 5251: train. loss = 0.0674Batch 599 / 5251: train. loss = 0.0673Batch 699 / 5251: train. loss = 0.0674Batch 799 / 5251: train. loss = 0.0674Batch 899 / 5251: train. loss = 0.0674Batch 999 / 5251: train. loss = 0.0674Batch 1099 / 5251: train. loss = 0.0674Batch 1199 / 5251: train. loss = 0.0673Batch 1299 / 5251: train. loss = 0.0674Batch 1399 / 5251: train. loss = 0.0674Batch 1499 / 5251: train. loss = 0.0673Batch 1599 / 5251: train. loss = 0.0673Batch 1699 / 5251: train. loss = 0.0673Batch 1799 / 5251: train. loss = 0.0673Batch 1899 / 5251: train. loss = 0.0673Batch 1999 / 5251: train. loss = 0.0673Batch 2099 / 5251: train. loss = 0.0673Batch 2199 / 5251: train. loss = 0.0673Batch 2299 / 5251: train. loss = 0.0673Batch 2399 / 5251: train. loss = 0.0673Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0673Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0673Batch 3199 / 5251: train. loss = 0.0673Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch 18 / 20: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.0064, time = 33.767731 s
Batch 99 / 5251: train. loss = 0.0668Batch 199 / 5251: train. loss = 0.0671Batch 299 / 5251: train. loss = 0.0671Batch 399 / 5251: train. loss = 0.0672Batch 499 / 5251: train. loss = 0.0672Batch 599 / 5251: train. loss = 0.0671Batch 699 / 5251: train. loss = 0.0671Batch 799 / 5251: train. loss = 0.0671Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0670Batch 1099 / 5251: train. loss = 0.0669Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0670Batch 1399 / 5251: train. loss = 0.0670Batch 1499 / 5251: train. loss = 0.0671Batch 1599 / 5251: train. loss = 0.0671Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0671Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0672Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch 19 / 20: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.0034, time = 33.771899 s
Batch 99 / 5251: train. loss = 0.0682Batch 199 / 5251: train. loss = 0.0678Batch 299 / 5251: train. loss = 0.0677Batch 399 / 5251: train. loss = 0.0674Batch 499 / 5251: train. loss = 0.0675Batch 599 / 5251: train. loss = 0.0675Batch 699 / 5251: train. loss = 0.0675Batch 799 / 5251: train. loss = 0.0674Batch 899 / 5251: train. loss = 0.0674Batch 999 / 5251: train. loss = 0.0673Batch 1099 / 5251: train. loss = 0.0674Batch 1199 / 5251: train. loss = 0.0673Batch 1299 / 5251: train. loss = 0.0673Batch 1399 / 5251: train. loss = 0.0674Batch 1499 / 5251: train. loss = 0.0674Batch 1599 / 5251: train. loss = 0.0674Batch 1699 / 5251: train. loss = 0.0674Batch 1799 / 5251: train. loss = 0.0674Batch 1899 / 5251: train. loss = 0.0674Batch 1999 / 5251: train. loss = 0.0674Batch 2099 / 5251: train. loss = 0.0673Batch 2199 / 5251: train. loss = 0.0673Batch 2299 / 5251: train. loss = 0.0673Batch 2399 / 5251: train. loss = 0.0673Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch 20 / 20: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.0016, time = 33.769152 s
Batch 99 / 5251: train. loss = 0.0667Batch 199 / 5251: train. loss = 0.0671Batch 299 / 5251: train. loss = 0.0672Batch 399 / 5251: train. loss = 0.0671Batch 499 / 5251: train. loss = 0.0672Batch 599 / 5251: train. loss = 0.0672Batch 699 / 5251: train. loss = 0.0672Batch 799 / 5251: train. loss = 0.0673Batch 899 / 5251: train. loss = 0.0673Batch 999 / 5251: train. loss = 0.0672Batch 1099 / 5251: train. loss = 0.0672Batch 1199 / 5251: train. loss = 0.0672Batch 1299 / 5251: train. loss = 0.0672Batch 1399 / 5251: train. loss = 0.0672Batch 1499 / 5251: train. loss = 0.0672Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0671Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch  1 / 40: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.1000, time = 33.811201 s
Batch 99 / 5251: train. loss = 0.0677Batch 199 / 5251: train. loss = 0.0675Batch 299 / 5251: train. loss = 0.0674Batch 399 / 5251: train. loss = 0.0673Batch 499 / 5251: train. loss = 0.0672Batch 599 / 5251: train. loss = 0.0674Batch 699 / 5251: train. loss = 0.0674Batch 799 / 5251: train. loss = 0.0673Batch 899 / 5251: train. loss = 0.0674Batch 999 / 5251: train. loss = 0.0674Batch 1099 / 5251: train. loss = 0.0673Batch 1199 / 5251: train. loss = 0.0673Batch 1299 / 5251: train. loss = 0.0673Batch 1399 / 5251: train. loss = 0.0673Batch 1499 / 5251: train. loss = 0.0673Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0672Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0671Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0671Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0671Batch 3699 / 5251: train. loss = 0.0671Batch 3799 / 5251: train. loss = 0.0671Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch  2 / 40: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.0998, time = 33.764684 s
Batch 99 / 5251: train. loss = 0.0674Batch 199 / 5251: train. loss = 0.0670Batch 299 / 5251: train. loss = 0.0669Batch 399 / 5251: train. loss = 0.0669Batch 499 / 5251: train. loss = 0.0668Batch 599 / 5251: train. loss = 0.0669Batch 699 / 5251: train. loss = 0.0669Batch 799 / 5251: train. loss = 0.0670Batch 899 / 5251: train. loss = 0.0669Batch 999 / 5251: train. loss = 0.0670Batch 1099 / 5251: train. loss = 0.0670Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0670Batch 1399 / 5251: train. loss = 0.0671Batch 1499 / 5251: train. loss = 0.0671Batch 1599 / 5251: train. loss = 0.0671Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0671Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0671Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch  3 / 40: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.0994, time = 33.653827 s
Batch 99 / 5251: train. loss = 0.0671Batch 199 / 5251: train. loss = 0.0673Batch 299 / 5251: train. loss = 0.0673Batch 399 / 5251: train. loss = 0.0672Batch 499 / 5251: train. loss = 0.0672Batch 599 / 5251: train. loss = 0.0672Batch 699 / 5251: train. loss = 0.0672Batch 799 / 5251: train. loss = 0.0672Batch 899 / 5251: train. loss = 0.0672Batch 999 / 5251: train. loss = 0.0672Batch 1099 / 5251: train. loss = 0.0673Batch 1199 / 5251: train. loss = 0.0673Batch 1299 / 5251: train. loss = 0.0673Batch 1399 / 5251: train. loss = 0.0672Batch 1499 / 5251: train. loss = 0.0672Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0672Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0673Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0673Batch 2899 / 5251: train. loss = 0.0673Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0673Batch 3199 / 5251: train. loss = 0.0673Batch 3299 / 5251: train. loss = 0.0673Batch 3399 / 5251: train. loss = 0.0673Batch 3499 / 5251: train. loss = 0.0673Batch 3599 / 5251: train. loss = 0.0673Batch 3699 / 5251: train. loss = 0.0673Batch 3799 / 5251: train. loss = 0.0673Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0673Batch 4099 / 5251: train. loss = 0.0673Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch  4 / 40: train. loss = 0.0672, val. loss = 0.0734, lr. = 0.0986, time = 33.735218 s
Batch 99 / 5251: train. loss = 0.0671Batch 199 / 5251: train. loss = 0.0671Batch 299 / 5251: train. loss = 0.0673Batch 399 / 5251: train. loss = 0.0673Batch 499 / 5251: train. loss = 0.0673Batch 599 / 5251: train. loss = 0.0673Batch 699 / 5251: train. loss = 0.0672Batch 799 / 5251: train. loss = 0.0672Batch 899 / 5251: train. loss = 0.0673Batch 999 / 5251: train. loss = 0.0673Batch 1099 / 5251: train. loss = 0.0673Batch 1199 / 5251: train. loss = 0.0673Batch 1299 / 5251: train. loss = 0.0673Batch 1399 / 5251: train. loss = 0.0673Batch 1499 / 5251: train. loss = 0.0672Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0673Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0673Batch 2199 / 5251: train. loss = 0.0673Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch  5 / 40: train. loss = 0.0672, val. loss = 0.0735, lr. = 0.0976, time = 33.669787 s
Batch 99 / 5251: train. loss = 0.0669Batch 199 / 5251: train. loss = 0.0668Batch 299 / 5251: train. loss = 0.0668Batch 399 / 5251: train. loss = 0.0669Batch 499 / 5251: train. loss = 0.0669Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0671Batch 799 / 5251: train. loss = 0.0671Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0671Batch 1099 / 5251: train. loss = 0.0671Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0670Batch 1399 / 5251: train. loss = 0.0670Batch 1499 / 5251: train. loss = 0.0670Batch 1599 / 5251: train. loss = 0.0670Batch 1699 / 5251: train. loss = 0.0670Batch 1799 / 5251: train. loss = 0.0670Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0671Batch 2599 / 5251: train. loss = 0.0671Batch 2699 / 5251: train. loss = 0.0671Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0671Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0671Batch 3699 / 5251: train. loss = 0.0671Batch 3799 / 5251: train. loss = 0.0671Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch  6 / 40: train. loss = 0.0672, val. loss = 0.0734, lr. = 0.0962, time = 33.736698 s
Batch 99 / 5251: train. loss = 0.0667Batch 199 / 5251: train. loss = 0.0668Batch 299 / 5251: train. loss = 0.0666Batch 399 / 5251: train. loss = 0.0669Batch 499 / 5251: train. loss = 0.0671Batch 599 / 5251: train. loss = 0.0672Batch 699 / 5251: train. loss = 0.0671Batch 799 / 5251: train. loss = 0.0671Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0672Batch 1099 / 5251: train. loss = 0.0672Batch 1199 / 5251: train. loss = 0.0672Batch 1299 / 5251: train. loss = 0.0672Batch 1399 / 5251: train. loss = 0.0672Batch 1499 / 5251: train. loss = 0.0673Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0672Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch  7 / 40: train. loss = 0.0672, val. loss = 0.0734, lr. = 0.0946, time = 33.648929 s
Batch 99 / 5251: train. loss = 0.0676Batch 199 / 5251: train. loss = 0.0670Batch 299 / 5251: train. loss = 0.0673Batch 399 / 5251: train. loss = 0.0674Batch 499 / 5251: train. loss = 0.0674Batch 599 / 5251: train. loss = 0.0673Batch 699 / 5251: train. loss = 0.0674Batch 799 / 5251: train. loss = 0.0674Batch 899 / 5251: train. loss = 0.0673Batch 999 / 5251: train. loss = 0.0672Batch 1099 / 5251: train. loss = 0.0672Batch 1199 / 5251: train. loss = 0.0672Batch 1299 / 5251: train. loss = 0.0672Batch 1399 / 5251: train. loss = 0.0672Batch 1499 / 5251: train. loss = 0.0672Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0671Batch 2099 / 5251: train. loss = 0.0671Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0671Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0671Batch 3699 / 5251: train. loss = 0.0671Batch 3799 / 5251: train. loss = 0.0671Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0671Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0671Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch  8 / 40: train. loss = 0.0672, val. loss = 0.0734, lr. = 0.0926, time = 33.837916 s
Batch 99 / 5251: train. loss = 0.0671Batch 199 / 5251: train. loss = 0.0670Batch 299 / 5251: train. loss = 0.0670Batch 399 / 5251: train. loss = 0.0671Batch 499 / 5251: train. loss = 0.0670Batch 599 / 5251: train. loss = 0.0669Batch 699 / 5251: train. loss = 0.0670Batch 799 / 5251: train. loss = 0.0670Batch 899 / 5251: train. loss = 0.0670Batch 999 / 5251: train. loss = 0.0671Batch 1099 / 5251: train. loss = 0.0671Batch 1199 / 5251: train. loss = 0.0672Batch 1299 / 5251: train. loss = 0.0672Batch 1399 / 5251: train. loss = 0.0671Batch 1499 / 5251: train. loss = 0.0672Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0672Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0671Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0671Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0671Batch 4299 / 5251: train. loss = 0.0671Batch 4399 / 5251: train. loss = 0.0671Batch 4499 / 5251: train. loss = 0.0671Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch  9 / 40: train. loss = 0.0672, val. loss = 0.0734, lr. = 0.0905, time = 33.854063 s
Batch 99 / 5251: train. loss = 0.0669Batch 199 / 5251: train. loss = 0.0670Batch 299 / 5251: train. loss = 0.0668Batch 399 / 5251: train. loss = 0.0669Batch 499 / 5251: train. loss = 0.0671Batch 599 / 5251: train. loss = 0.0672Batch 699 / 5251: train. loss = 0.0672Batch 799 / 5251: train. loss = 0.0672Batch 899 / 5251: train. loss = 0.0672Batch 999 / 5251: train. loss = 0.0672Batch 1099 / 5251: train. loss = 0.0672Batch 1199 / 5251: train. loss = 0.0672Batch 1299 / 5251: train. loss = 0.0672Batch 1399 / 5251: train. loss = 0.0672Batch 1499 / 5251: train. loss = 0.0672Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0671Batch 2399 / 5251: train. loss = 0.0671Batch 2499 / 5251: train. loss = 0.0671Batch 2599 / 5251: train. loss = 0.0671Batch 2699 / 5251: train. loss = 0.0671Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0672Batch 4699 / 5251: train. loss = 0.0672Batch 4799 / 5251: train. loss = 0.0672Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch 10 / 40: train. loss = 0.0672, val. loss = 0.0734, lr. = 0.0880, time = 33.625573 s
Batch 99 / 5251: train. loss = 0.0677Batch 199 / 5251: train. loss = 0.0674Batch 299 / 5251: train. loss = 0.0672Batch 399 / 5251: train. loss = 0.0671Batch 499 / 5251: train. loss = 0.0673Batch 599 / 5251: train. loss = 0.0672Batch 699 / 5251: train. loss = 0.0671Batch 799 / 5251: train. loss = 0.0671Batch 899 / 5251: train. loss = 0.0670Batch 999 / 5251: train. loss = 0.0670Batch 1099 / 5251: train. loss = 0.0669Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0670Batch 1399 / 5251: train. loss = 0.0670Batch 1499 / 5251: train. loss = 0.0669Batch 1599 / 5251: train. loss = 0.0670Batch 1699 / 5251: train. loss = 0.0669Batch 1799 / 5251: train. loss = 0.0670Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0671Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0671Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0671Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0671Batch 5099 / 5251: train. loss = 0.0671Batch 5199 / 5251: train. loss = 0.0672Epoch 11 / 40: train. loss = 0.0672, val. loss = 0.0734, lr. = 0.0854, time = 33.719747 s
Batch 99 / 5251: train. loss = 0.0666Batch 199 / 5251: train. loss = 0.0668Batch 299 / 5251: train. loss = 0.0666Batch 399 / 5251: train. loss = 0.0668Batch 499 / 5251: train. loss = 0.0670Batch 599 / 5251: train. loss = 0.0671Batch 699 / 5251: train. loss = 0.0671Batch 799 / 5251: train. loss = 0.0671Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0672Batch 1099 / 5251: train. loss = 0.0672Batch 1199 / 5251: train. loss = 0.0672Batch 1299 / 5251: train. loss = 0.0672Batch 1399 / 5251: train. loss = 0.0672Batch 1499 / 5251: train. loss = 0.0672Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0672Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0673Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0672Batch 3599 / 5251: train. loss = 0.0672Batch 3699 / 5251: train. loss = 0.0673Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0672Batch 3999 / 5251: train. loss = 0.0672Batch 4099 / 5251: train. loss = 0.0672Batch 4199 / 5251: train. loss = 0.0672Batch 4299 / 5251: train. loss = 0.0672Batch 4399 / 5251: train. loss = 0.0672Batch 4499 / 5251: train. loss = 0.0672Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0671Batch 4899 / 5251: train. loss = 0.0672Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0672Batch 5199 / 5251: train. loss = 0.0672Epoch 12 / 40: train. loss = 0.0672, val. loss = 0.0734, lr. = 0.0825, time = 33.621279 s
Batch 99 / 5251: train. loss = 0.0674Batch 199 / 5251: train. loss = 0.0673Batch 299 / 5251: train. loss = 0.0670Batch 399 / 5251: train. loss = 0.0672Batch 499 / 5251: train. loss = 0.0673Batch 599 / 5251: train. loss = 0.0671Batch 699 / 5251: train. loss = 0.0671Batch 799 / 5251: train. loss = 0.0672Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0671Batch 1099 / 5251: train. loss = 0.0670Batch 1199 / 5251: train. loss = 0.0671Batch 1299 / 5251: train. loss = 0.0670Batch 1399 / 5251: train. loss = 0.0671Batch 1499 / 5251: train. loss = 0.0671Batch 1599 / 5251: train. loss = 0.0671Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0671Batch 1899 / 5251: train. loss = 0.0671Batch 1999 / 5251: train. loss = 0.0671Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0672Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0671Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0671Batch 3699 / 5251: train. loss = 0.0672Batch 3799 / 5251: train. loss = 0.0672Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0671Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0671Batch 4299 / 5251: train. loss = 0.0671Batch 4399 / 5251: train. loss = 0.0671Batch 4499 / 5251: train. loss = 0.0671Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0671Batch 4899 / 5251: train. loss = 0.0671Batch 4999 / 5251: train. loss = 0.0672Batch 5099 / 5251: train. loss = 0.0671Batch 5199 / 5251: train. loss = 0.0672Epoch 13 / 40: train. loss = 0.0671, val. loss = 0.0734, lr. = 0.0794, time = 33.752414 s
Batch 99 / 5251: train. loss = 0.0666Batch 199 / 5251: train. loss = 0.0666Batch 299 / 5251: train. loss = 0.0668Batch 399 / 5251: train. loss = 0.0669Batch 499 / 5251: train. loss = 0.0669Batch 599 / 5251: train. loss = 0.0669Batch 699 / 5251: train. loss = 0.0668Batch 799 / 5251: train. loss = 0.0668Batch 899 / 5251: train. loss = 0.0668Batch 999 / 5251: train. loss = 0.0668Batch 1099 / 5251: train. loss = 0.0669Batch 1199 / 5251: train. loss = 0.0669Batch 1299 / 5251: train. loss = 0.0668Batch 1399 / 5251: train. loss = 0.0668Batch 1499 / 5251: train. loss = 0.0669Batch 1599 / 5251: train. loss = 0.0669Batch 1699 / 5251: train. loss = 0.0669Batch 1799 / 5251: train. loss = 0.0670Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0670Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0671Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0671Batch 3699 / 5251: train. loss = 0.0671Batch 3799 / 5251: train. loss = 0.0671Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0671Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0671Batch 4299 / 5251: train. loss = 0.0671Batch 4399 / 5251: train. loss = 0.0671Batch 4499 / 5251: train. loss = 0.0671Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0671Batch 4899 / 5251: train. loss = 0.0671Batch 4999 / 5251: train. loss = 0.0671Batch 5099 / 5251: train. loss = 0.0671Batch 5199 / 5251: train. loss = 0.0671Epoch 14 / 40: train. loss = 0.0671, val. loss = 0.0734, lr. = 0.0761, time = 33.638658 s
Batch 99 / 5251: train. loss = 0.0675Batch 199 / 5251: train. loss = 0.0679Batch 299 / 5251: train. loss = 0.0678Batch 399 / 5251: train. loss = 0.0675Batch 499 / 5251: train. loss = 0.0675Batch 599 / 5251: train. loss = 0.0675Batch 699 / 5251: train. loss = 0.0674Batch 799 / 5251: train. loss = 0.0673Batch 899 / 5251: train. loss = 0.0672Batch 999 / 5251: train. loss = 0.0672Batch 1099 / 5251: train. loss = 0.0671Batch 1199 / 5251: train. loss = 0.0671Batch 1299 / 5251: train. loss = 0.0671Batch 1399 / 5251: train. loss = 0.0671Batch 1499 / 5251: train. loss = 0.0671Batch 1599 / 5251: train. loss = 0.0671Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0671Batch 1899 / 5251: train. loss = 0.0671Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0671Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0671Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0671Batch 3699 / 5251: train. loss = 0.0671Batch 3799 / 5251: train. loss = 0.0671Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0671Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0671Batch 4299 / 5251: train. loss = 0.0671Batch 4399 / 5251: train. loss = 0.0671Batch 4499 / 5251: train. loss = 0.0671Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0671Batch 4899 / 5251: train. loss = 0.0671Batch 4999 / 5251: train. loss = 0.0671Batch 5099 / 5251: train. loss = 0.0671Batch 5199 / 5251: train. loss = 0.0671Epoch 15 / 40: train. loss = 0.0671, val. loss = 0.0734, lr. = 0.0727, time = 33.866414 s
Batch 99 / 5251: train. loss = 0.0667Batch 199 / 5251: train. loss = 0.0668Batch 299 / 5251: train. loss = 0.0671Batch 399 / 5251: train. loss = 0.0669Batch 499 / 5251: train. loss = 0.0669Batch 599 / 5251: train. loss = 0.0669Batch 699 / 5251: train. loss = 0.0670Batch 799 / 5251: train. loss = 0.0670Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0670Batch 1099 / 5251: train. loss = 0.0670Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0671Batch 1399 / 5251: train. loss = 0.0671Batch 1499 / 5251: train. loss = 0.0672Batch 1599 / 5251: train. loss = 0.0671Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0671Batch 1999 / 5251: train. loss = 0.0671Batch 2099 / 5251: train. loss = 0.0671Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0671Batch 2399 / 5251: train. loss = 0.0671Batch 2499 / 5251: train. loss = 0.0671Batch 2599 / 5251: train. loss = 0.0671Batch 2699 / 5251: train. loss = 0.0671Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0671Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0671Batch 3699 / 5251: train. loss = 0.0671Batch 3799 / 5251: train. loss = 0.0671Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0671Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0671Batch 4299 / 5251: train. loss = 0.0671Batch 4399 / 5251: train. loss = 0.0671Batch 4499 / 5251: train. loss = 0.0671Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0671Batch 4899 / 5251: train. loss = 0.0671Batch 4999 / 5251: train. loss = 0.0671Batch 5099 / 5251: train. loss = 0.0671Batch 5199 / 5251: train. loss = 0.0671Epoch 16 / 40: train. loss = 0.0671, val. loss = 0.0734, lr. = 0.0692, time = 33.810618 s
Batch 99 / 5251: train. loss = 0.0670Batch 199 / 5251: train. loss = 0.0673Batch 299 / 5251: train. loss = 0.0671Batch 399 / 5251: train. loss = 0.0671Batch 499 / 5251: train. loss = 0.0671Batch 599 / 5251: train. loss = 0.0672Batch 699 / 5251: train. loss = 0.0672Batch 799 / 5251: train. loss = 0.0671Batch 899 / 5251: train. loss = 0.0672Batch 999 / 5251: train. loss = 0.0672Batch 1099 / 5251: train. loss = 0.0672Batch 1199 / 5251: train. loss = 0.0672Batch 1299 / 5251: train. loss = 0.0672Batch 1399 / 5251: train. loss = 0.0672Batch 1499 / 5251: train. loss = 0.0672Batch 1599 / 5251: train. loss = 0.0671Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0671Batch 1899 / 5251: train. loss = 0.0671Batch 1999 / 5251: train. loss = 0.0671Batch 2099 / 5251: train. loss = 0.0671Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0671Batch 2399 / 5251: train. loss = 0.0671Batch 2499 / 5251: train. loss = 0.0671Batch 2599 / 5251: train. loss = 0.0671Batch 2699 / 5251: train. loss = 0.0671Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0671Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0671Batch 3699 / 5251: train. loss = 0.0671Batch 3799 / 5251: train. loss = 0.0671Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0671Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0671Batch 4299 / 5251: train. loss = 0.0671Batch 4399 / 5251: train. loss = 0.0671Batch 4499 / 5251: train. loss = 0.0671Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0671Batch 4899 / 5251: train. loss = 0.0671Batch 4999 / 5251: train. loss = 0.0671Batch 5099 / 5251: train. loss = 0.0671Batch 5199 / 5251: train. loss = 0.0671Epoch 17 / 40: train. loss = 0.0671, val. loss = 0.0734, lr. = 0.0655, time = 33.814103 s
Batch 99 / 5251: train. loss = 0.0670Batch 199 / 5251: train. loss = 0.0665Batch 299 / 5251: train. loss = 0.0670Batch 399 / 5251: train. loss = 0.0670Batch 499 / 5251: train. loss = 0.0670Batch 599 / 5251: train. loss = 0.0671Batch 699 / 5251: train. loss = 0.0670Batch 799 / 5251: train. loss = 0.0671Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0670Batch 1099 / 5251: train. loss = 0.0670Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0670Batch 1399 / 5251: train. loss = 0.0670Batch 1499 / 5251: train. loss = 0.0670Batch 1599 / 5251: train. loss = 0.0670Batch 1699 / 5251: train. loss = 0.0670Batch 1799 / 5251: train. loss = 0.0670Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0671Batch 2599 / 5251: train. loss = 0.0671Batch 2699 / 5251: train. loss = 0.0671Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0670Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0671Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0671Batch 4899 / 5251: train. loss = 0.0671Batch 4999 / 5251: train. loss = 0.0671Batch 5099 / 5251: train. loss = 0.0671Batch 5199 / 5251: train. loss = 0.0671Epoch 18 / 40: train. loss = 0.0671, val. loss = 0.0733, lr. = 0.0617, time = 33.886119 s
Batch 99 / 5251: train. loss = 0.0676Batch 199 / 5251: train. loss = 0.0674Batch 299 / 5251: train. loss = 0.0672Batch 399 / 5251: train. loss = 0.0670Batch 499 / 5251: train. loss = 0.0670Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0671Batch 799 / 5251: train. loss = 0.0672Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0672Batch 1099 / 5251: train. loss = 0.0672Batch 1199 / 5251: train. loss = 0.0672Batch 1299 / 5251: train. loss = 0.0672Batch 1399 / 5251: train. loss = 0.0673Batch 1499 / 5251: train. loss = 0.0673Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0673Batch 1799 / 5251: train. loss = 0.0673Batch 1899 / 5251: train. loss = 0.0672Batch 1999 / 5251: train. loss = 0.0672Batch 2099 / 5251: train. loss = 0.0672Batch 2199 / 5251: train. loss = 0.0672Batch 2299 / 5251: train. loss = 0.0672Batch 2399 / 5251: train. loss = 0.0672Batch 2499 / 5251: train. loss = 0.0672Batch 2599 / 5251: train. loss = 0.0672Batch 2699 / 5251: train. loss = 0.0672Batch 2799 / 5251: train. loss = 0.0672Batch 2899 / 5251: train. loss = 0.0672Batch 2999 / 5251: train. loss = 0.0672Batch 3099 / 5251: train. loss = 0.0672Batch 3199 / 5251: train. loss = 0.0672Batch 3299 / 5251: train. loss = 0.0672Batch 3399 / 5251: train. loss = 0.0672Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0671Batch 3699 / 5251: train. loss = 0.0671Batch 3799 / 5251: train. loss = 0.0671Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0671Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0671Batch 4299 / 5251: train. loss = 0.0671Batch 4399 / 5251: train. loss = 0.0671Batch 4499 / 5251: train. loss = 0.0671Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0671Batch 4899 / 5251: train. loss = 0.0671Batch 4999 / 5251: train. loss = 0.0671Batch 5099 / 5251: train. loss = 0.0671Batch 5199 / 5251: train. loss = 0.0671Epoch 19 / 40: train. loss = 0.0671, val. loss = 0.0733, lr. = 0.0579, time = 33.782446 s
Batch 99 / 5251: train. loss = 0.0667Batch 199 / 5251: train. loss = 0.0674Batch 299 / 5251: train. loss = 0.0674Batch 399 / 5251: train. loss = 0.0671Batch 499 / 5251: train. loss = 0.0670Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0670Batch 799 / 5251: train. loss = 0.0670Batch 899 / 5251: train. loss = 0.0670Batch 999 / 5251: train. loss = 0.0670Batch 1099 / 5251: train. loss = 0.0670Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0669Batch 1399 / 5251: train. loss = 0.0670Batch 1499 / 5251: train. loss = 0.0670Batch 1599 / 5251: train. loss = 0.0670Batch 1699 / 5251: train. loss = 0.0669Batch 1799 / 5251: train. loss = 0.0669Batch 1899 / 5251: train. loss = 0.0669Batch 1999 / 5251: train. loss = 0.0669Batch 2099 / 5251: train. loss = 0.0669Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0670Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0671Batch 5099 / 5251: train. loss = 0.0671Batch 5199 / 5251: train. loss = 0.0671Epoch 20 / 40: train. loss = 0.0671, val. loss = 0.0733, lr. = 0.0540, time = 33.891123 s
Batch 99 / 5251: train. loss = 0.0674Batch 199 / 5251: train. loss = 0.0669Batch 299 / 5251: train. loss = 0.0668Batch 399 / 5251: train. loss = 0.0670Batch 499 / 5251: train. loss = 0.0670Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0669Batch 799 / 5251: train. loss = 0.0671Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0671Batch 1099 / 5251: train. loss = 0.0671Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0670Batch 1399 / 5251: train. loss = 0.0670Batch 1499 / 5251: train. loss = 0.0670Batch 1599 / 5251: train. loss = 0.0670Batch 1699 / 5251: train. loss = 0.0670Batch 1799 / 5251: train. loss = 0.0670Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0671Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0671Batch 4299 / 5251: train. loss = 0.0671Batch 4399 / 5251: train. loss = 0.0671Batch 4499 / 5251: train. loss = 0.0671Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0671Batch 4899 / 5251: train. loss = 0.0671Batch 4999 / 5251: train. loss = 0.0671Batch 5099 / 5251: train. loss = 0.0671Batch 5199 / 5251: train. loss = 0.0671Epoch 21 / 40: train. loss = 0.0671, val. loss = 0.0733, lr. = 0.0501, time = 33.729469 s
Batch 99 / 5251: train. loss = 0.0669Batch 199 / 5251: train. loss = 0.0668Batch 299 / 5251: train. loss = 0.0670Batch 399 / 5251: train. loss = 0.0672Batch 499 / 5251: train. loss = 0.0672Batch 599 / 5251: train. loss = 0.0673Batch 699 / 5251: train. loss = 0.0673Batch 799 / 5251: train. loss = 0.0673Batch 899 / 5251: train. loss = 0.0672Batch 999 / 5251: train. loss = 0.0671Batch 1099 / 5251: train. loss = 0.0672Batch 1199 / 5251: train. loss = 0.0672Batch 1299 / 5251: train. loss = 0.0672Batch 1399 / 5251: train. loss = 0.0672Batch 1499 / 5251: train. loss = 0.0672Batch 1599 / 5251: train. loss = 0.0671Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0671Batch 1899 / 5251: train. loss = 0.0671Batch 1999 / 5251: train. loss = 0.0671Batch 2099 / 5251: train. loss = 0.0671Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0671Batch 2399 / 5251: train. loss = 0.0671Batch 2499 / 5251: train. loss = 0.0671Batch 2599 / 5251: train. loss = 0.0671Batch 2699 / 5251: train. loss = 0.0671Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0671Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0671Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 22 / 40: train. loss = 0.0671, val. loss = 0.0733, lr. = 0.0461, time = 33.817352 s
Batch 99 / 5251: train. loss = 0.0672Batch 199 / 5251: train. loss = 0.0670Batch 299 / 5251: train. loss = 0.0669Batch 399 / 5251: train. loss = 0.0669Batch 499 / 5251: train. loss = 0.0669Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0669Batch 799 / 5251: train. loss = 0.0669Batch 899 / 5251: train. loss = 0.0670Batch 999 / 5251: train. loss = 0.0669Batch 1099 / 5251: train. loss = 0.0670Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0671Batch 1399 / 5251: train. loss = 0.0671Batch 1499 / 5251: train. loss = 0.0671Batch 1599 / 5251: train. loss = 0.0672Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0671Batch 1899 / 5251: train. loss = 0.0671Batch 1999 / 5251: train. loss = 0.0671Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0670Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0671Batch 4099 / 5251: train. loss = 0.0671Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 23 / 40: train. loss = 0.0670, val. loss = 0.0733, lr. = 0.0422, time = 33.787368 s
Batch 99 / 5251: train. loss = 0.0680Batch 199 / 5251: train. loss = 0.0679Batch 299 / 5251: train. loss = 0.0677Batch 399 / 5251: train. loss = 0.0677Batch 499 / 5251: train. loss = 0.0674Batch 599 / 5251: train. loss = 0.0675Batch 699 / 5251: train. loss = 0.0674Batch 799 / 5251: train. loss = 0.0674Batch 899 / 5251: train. loss = 0.0674Batch 999 / 5251: train. loss = 0.0674Batch 1099 / 5251: train. loss = 0.0674Batch 1199 / 5251: train. loss = 0.0674Batch 1299 / 5251: train. loss = 0.0674Batch 1399 / 5251: train. loss = 0.0673Batch 1499 / 5251: train. loss = 0.0673Batch 1599 / 5251: train. loss = 0.0673Batch 1699 / 5251: train. loss = 0.0672Batch 1799 / 5251: train. loss = 0.0672Batch 1899 / 5251: train. loss = 0.0671Batch 1999 / 5251: train. loss = 0.0671Batch 2099 / 5251: train. loss = 0.0671Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0671Batch 2399 / 5251: train. loss = 0.0671Batch 2499 / 5251: train. loss = 0.0671Batch 2599 / 5251: train. loss = 0.0671Batch 2699 / 5251: train. loss = 0.0671Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0670Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0671Batch 4299 / 5251: train. loss = 0.0671Batch 4399 / 5251: train. loss = 0.0671Batch 4499 / 5251: train. loss = 0.0671Batch 4599 / 5251: train. loss = 0.0671Batch 4699 / 5251: train. loss = 0.0671Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 24 / 40: train. loss = 0.0670, val. loss = 0.0733, lr. = 0.0384, time = 33.886051 s
Batch 99 / 5251: train. loss = 0.0665Batch 199 / 5251: train. loss = 0.0666Batch 299 / 5251: train. loss = 0.0668Batch 399 / 5251: train. loss = 0.0668Batch 499 / 5251: train. loss = 0.0669Batch 599 / 5251: train. loss = 0.0669Batch 699 / 5251: train. loss = 0.0670Batch 799 / 5251: train. loss = 0.0670Batch 899 / 5251: train. loss = 0.0670Batch 999 / 5251: train. loss = 0.0671Batch 1099 / 5251: train. loss = 0.0671Batch 1199 / 5251: train. loss = 0.0671Batch 1299 / 5251: train. loss = 0.0670Batch 1399 / 5251: train. loss = 0.0670Batch 1499 / 5251: train. loss = 0.0671Batch 1599 / 5251: train. loss = 0.0671Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0671Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0671Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0670Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0671Batch 3699 / 5251: train. loss = 0.0671Batch 3799 / 5251: train. loss = 0.0671Batch 3899 / 5251: train. loss = 0.0671Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 25 / 40: train. loss = 0.0670, val. loss = 0.0733, lr. = 0.0346, time = 33.846578 s
Batch 99 / 5251: train. loss = 0.0678Batch 199 / 5251: train. loss = 0.0675Batch 299 / 5251: train. loss = 0.0673Batch 399 / 5251: train. loss = 0.0672Batch 499 / 5251: train. loss = 0.0670Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0668Batch 799 / 5251: train. loss = 0.0668Batch 899 / 5251: train. loss = 0.0668Batch 999 / 5251: train. loss = 0.0668Batch 1099 / 5251: train. loss = 0.0668Batch 1199 / 5251: train. loss = 0.0668Batch 1299 / 5251: train. loss = 0.0669Batch 1399 / 5251: train. loss = 0.0669Batch 1499 / 5251: train. loss = 0.0669Batch 1599 / 5251: train. loss = 0.0669Batch 1699 / 5251: train. loss = 0.0669Batch 1799 / 5251: train. loss = 0.0669Batch 1899 / 5251: train. loss = 0.0669Batch 1999 / 5251: train. loss = 0.0669Batch 2099 / 5251: train. loss = 0.0669Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0671Batch 4399 / 5251: train. loss = 0.0671Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 26 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0309, time = 33.723127 s
Batch 99 / 5251: train. loss = 0.0666Batch 199 / 5251: train. loss = 0.0670Batch 299 / 5251: train. loss = 0.0669Batch 399 / 5251: train. loss = 0.0669Batch 499 / 5251: train. loss = 0.0669Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0669Batch 799 / 5251: train. loss = 0.0670Batch 899 / 5251: train. loss = 0.0670Batch 999 / 5251: train. loss = 0.0670Batch 1099 / 5251: train. loss = 0.0669Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0669Batch 1399 / 5251: train. loss = 0.0669Batch 1499 / 5251: train. loss = 0.0670Batch 1599 / 5251: train. loss = 0.0670Batch 1699 / 5251: train. loss = 0.0670Batch 1799 / 5251: train. loss = 0.0669Batch 1899 / 5251: train. loss = 0.0669Batch 1999 / 5251: train. loss = 0.0669Batch 2099 / 5251: train. loss = 0.0669Batch 2199 / 5251: train. loss = 0.0669Batch 2299 / 5251: train. loss = 0.0669Batch 2399 / 5251: train. loss = 0.0669Batch 2499 / 5251: train. loss = 0.0669Batch 2599 / 5251: train. loss = 0.0669Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0670Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 27 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0274, time = 33.779537 s
Batch 99 / 5251: train. loss = 0.0663Batch 199 / 5251: train. loss = 0.0668Batch 299 / 5251: train. loss = 0.0669Batch 399 / 5251: train. loss = 0.0668Batch 499 / 5251: train. loss = 0.0669Batch 599 / 5251: train. loss = 0.0669Batch 699 / 5251: train. loss = 0.0668Batch 799 / 5251: train. loss = 0.0668Batch 899 / 5251: train. loss = 0.0668Batch 999 / 5251: train. loss = 0.0669Batch 1099 / 5251: train. loss = 0.0668Batch 1199 / 5251: train. loss = 0.0669Batch 1299 / 5251: train. loss = 0.0669Batch 1399 / 5251: train. loss = 0.0669Batch 1499 / 5251: train. loss = 0.0669Batch 1599 / 5251: train. loss = 0.0670Batch 1699 / 5251: train. loss = 0.0670Batch 1799 / 5251: train. loss = 0.0669Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 28 / 40: train. loss = 0.0670, val. loss = 0.0733, lr. = 0.0240, time = 33.733563 s
Batch 99 / 5251: train. loss = 0.0669Batch 199 / 5251: train. loss = 0.0668Batch 299 / 5251: train. loss = 0.0670Batch 399 / 5251: train. loss = 0.0671Batch 499 / 5251: train. loss = 0.0671Batch 599 / 5251: train. loss = 0.0669Batch 699 / 5251: train. loss = 0.0669Batch 799 / 5251: train. loss = 0.0670Batch 899 / 5251: train. loss = 0.0670Batch 999 / 5251: train. loss = 0.0670Batch 1099 / 5251: train. loss = 0.0670Batch 1199 / 5251: train. loss = 0.0671Batch 1299 / 5251: train. loss = 0.0671Batch 1399 / 5251: train. loss = 0.0671Batch 1499 / 5251: train. loss = 0.0671Batch 1599 / 5251: train. loss = 0.0670Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0671Batch 1899 / 5251: train. loss = 0.0671Batch 1999 / 5251: train. loss = 0.0671Batch 2099 / 5251: train. loss = 0.0671Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0671Batch 2399 / 5251: train. loss = 0.0671Batch 2499 / 5251: train. loss = 0.0671Batch 2599 / 5251: train. loss = 0.0671Batch 2699 / 5251: train. loss = 0.0671Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0671Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0671Batch 3499 / 5251: train. loss = 0.0671Batch 3599 / 5251: train. loss = 0.0671Batch 3699 / 5251: train. loss = 0.0671Batch 3799 / 5251: train. loss = 0.0671Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 29 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0207, time = 33.691416 s
Batch 99 / 5251: train. loss = 0.0666Batch 199 / 5251: train. loss = 0.0668Batch 299 / 5251: train. loss = 0.0670Batch 399 / 5251: train. loss = 0.0670Batch 499 / 5251: train. loss = 0.0671Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0668Batch 799 / 5251: train. loss = 0.0669Batch 899 / 5251: train. loss = 0.0669Batch 999 / 5251: train. loss = 0.0669Batch 1099 / 5251: train. loss = 0.0669Batch 1199 / 5251: train. loss = 0.0668Batch 1299 / 5251: train. loss = 0.0669Batch 1399 / 5251: train. loss = 0.0669Batch 1499 / 5251: train. loss = 0.0670Batch 1599 / 5251: train. loss = 0.0669Batch 1699 / 5251: train. loss = 0.0669Batch 1799 / 5251: train. loss = 0.0669Batch 1899 / 5251: train. loss = 0.0669Batch 1999 / 5251: train. loss = 0.0669Batch 2099 / 5251: train. loss = 0.0669Batch 2199 / 5251: train. loss = 0.0669Batch 2299 / 5251: train. loss = 0.0669Batch 2399 / 5251: train. loss = 0.0669Batch 2499 / 5251: train. loss = 0.0669Batch 2599 / 5251: train. loss = 0.0669Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0669Batch 2899 / 5251: train. loss = 0.0669Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0669Batch 3199 / 5251: train. loss = 0.0669Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0669Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0669Batch 3799 / 5251: train. loss = 0.0669Batch 3899 / 5251: train. loss = 0.0669Batch 3999 / 5251: train. loss = 0.0669Batch 4099 / 5251: train. loss = 0.0669Batch 4199 / 5251: train. loss = 0.0669Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0669Batch 4499 / 5251: train. loss = 0.0669Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 30 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0176, time = 33.626131 s
Batch 99 / 5251: train. loss = 0.0673Batch 199 / 5251: train. loss = 0.0669Batch 299 / 5251: train. loss = 0.0669Batch 399 / 5251: train. loss = 0.0671Batch 499 / 5251: train. loss = 0.0671Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0670Batch 799 / 5251: train. loss = 0.0670Batch 899 / 5251: train. loss = 0.0669Batch 999 / 5251: train. loss = 0.0669Batch 1099 / 5251: train. loss = 0.0668Batch 1199 / 5251: train. loss = 0.0668Batch 1299 / 5251: train. loss = 0.0669Batch 1399 / 5251: train. loss = 0.0669Batch 1499 / 5251: train. loss = 0.0669Batch 1599 / 5251: train. loss = 0.0669Batch 1699 / 5251: train. loss = 0.0669Batch 1799 / 5251: train. loss = 0.0669Batch 1899 / 5251: train. loss = 0.0669Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0669Batch 2199 / 5251: train. loss = 0.0669Batch 2299 / 5251: train. loss = 0.0669Batch 2399 / 5251: train. loss = 0.0669Batch 2499 / 5251: train. loss = 0.0669Batch 2599 / 5251: train. loss = 0.0669Batch 2699 / 5251: train. loss = 0.0669Batch 2799 / 5251: train. loss = 0.0669Batch 2899 / 5251: train. loss = 0.0669Batch 2999 / 5251: train. loss = 0.0669Batch 3099 / 5251: train. loss = 0.0669Batch 3199 / 5251: train. loss = 0.0669Batch 3299 / 5251: train. loss = 0.0669Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0669Batch 4099 / 5251: train. loss = 0.0669Batch 4199 / 5251: train. loss = 0.0669Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 31 / 40: train. loss = 0.0670, val. loss = 0.0733, lr. = 0.0147, time = 33.979557 s
Batch 99 / 5251: train. loss = 0.0677Batch 199 / 5251: train. loss = 0.0672Batch 299 / 5251: train. loss = 0.0670Batch 399 / 5251: train. loss = 0.0669Batch 499 / 5251: train. loss = 0.0670Batch 599 / 5251: train. loss = 0.0671Batch 699 / 5251: train. loss = 0.0671Batch 799 / 5251: train. loss = 0.0671Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0671Batch 1099 / 5251: train. loss = 0.0671Batch 1199 / 5251: train. loss = 0.0671Batch 1299 / 5251: train. loss = 0.0671Batch 1399 / 5251: train. loss = 0.0671Batch 1499 / 5251: train. loss = 0.0670Batch 1599 / 5251: train. loss = 0.0670Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0670Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0670Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 32 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0121, time = 33.833391 s
Batch 99 / 5251: train. loss = 0.0670Batch 199 / 5251: train. loss = 0.0666Batch 299 / 5251: train. loss = 0.0667Batch 399 / 5251: train. loss = 0.0667Batch 499 / 5251: train. loss = 0.0669Batch 599 / 5251: train. loss = 0.0668Batch 699 / 5251: train. loss = 0.0669Batch 799 / 5251: train. loss = 0.0669Batch 899 / 5251: train. loss = 0.0670Batch 999 / 5251: train. loss = 0.0670Batch 1099 / 5251: train. loss = 0.0670Batch 1199 / 5251: train. loss = 0.0671Batch 1299 / 5251: train. loss = 0.0671Batch 1399 / 5251: train. loss = 0.0671Batch 1499 / 5251: train. loss = 0.0671Batch 1599 / 5251: train. loss = 0.0671Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0671Batch 1899 / 5251: train. loss = 0.0671Batch 1999 / 5251: train. loss = 0.0671Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0671Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0671Batch 2899 / 5251: train. loss = 0.0671Batch 2999 / 5251: train. loss = 0.0671Batch 3099 / 5251: train. loss = 0.0671Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0671Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 33 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0096, time = 33.772393 s
Batch 99 / 5251: train. loss = 0.0670Batch 199 / 5251: train. loss = 0.0673Batch 299 / 5251: train. loss = 0.0669Batch 399 / 5251: train. loss = 0.0669Batch 499 / 5251: train. loss = 0.0668Batch 599 / 5251: train. loss = 0.0669Batch 699 / 5251: train. loss = 0.0669Batch 799 / 5251: train. loss = 0.0670Batch 899 / 5251: train. loss = 0.0669Batch 999 / 5251: train. loss = 0.0669Batch 1099 / 5251: train. loss = 0.0669Batch 1199 / 5251: train. loss = 0.0669Batch 1299 / 5251: train. loss = 0.0669Batch 1399 / 5251: train. loss = 0.0668Batch 1499 / 5251: train. loss = 0.0669Batch 1599 / 5251: train. loss = 0.0669Batch 1699 / 5251: train. loss = 0.0669Batch 1799 / 5251: train. loss = 0.0668Batch 1899 / 5251: train. loss = 0.0669Batch 1999 / 5251: train. loss = 0.0669Batch 2099 / 5251: train. loss = 0.0669Batch 2199 / 5251: train. loss = 0.0669Batch 2299 / 5251: train. loss = 0.0669Batch 2399 / 5251: train. loss = 0.0669Batch 2499 / 5251: train. loss = 0.0669Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0670Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0669Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 34 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0075, time = 33.852783 s
Batch 99 / 5251: train. loss = 0.0669Batch 199 / 5251: train. loss = 0.0670Batch 299 / 5251: train. loss = 0.0671Batch 399 / 5251: train. loss = 0.0670Batch 499 / 5251: train. loss = 0.0671Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0671Batch 799 / 5251: train. loss = 0.0670Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0671Batch 1099 / 5251: train. loss = 0.0671Batch 1199 / 5251: train. loss = 0.0671Batch 1299 / 5251: train. loss = 0.0671Batch 1399 / 5251: train. loss = 0.0671Batch 1499 / 5251: train. loss = 0.0671Batch 1599 / 5251: train. loss = 0.0670Batch 1699 / 5251: train. loss = 0.0671Batch 1799 / 5251: train. loss = 0.0670Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0669Batch 2499 / 5251: train. loss = 0.0669Batch 2599 / 5251: train. loss = 0.0669Batch 2699 / 5251: train. loss = 0.0669Batch 2799 / 5251: train. loss = 0.0669Batch 2899 / 5251: train. loss = 0.0669Batch 2999 / 5251: train. loss = 0.0669Batch 3099 / 5251: train. loss = 0.0669Batch 3199 / 5251: train. loss = 0.0669Batch 3299 / 5251: train. loss = 0.0669Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0669Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 35 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0055, time = 33.761064 s
Batch 99 / 5251: train. loss = 0.0672Batch 199 / 5251: train. loss = 0.0668Batch 299 / 5251: train. loss = 0.0668Batch 399 / 5251: train. loss = 0.0667Batch 499 / 5251: train. loss = 0.0669Batch 599 / 5251: train. loss = 0.0669Batch 699 / 5251: train. loss = 0.0669Batch 799 / 5251: train. loss = 0.0669Batch 899 / 5251: train. loss = 0.0669Batch 999 / 5251: train. loss = 0.0669Batch 1099 / 5251: train. loss = 0.0669Batch 1199 / 5251: train. loss = 0.0669Batch 1299 / 5251: train. loss = 0.0669Batch 1399 / 5251: train. loss = 0.0669Batch 1499 / 5251: train. loss = 0.0669Batch 1599 / 5251: train. loss = 0.0669Batch 1699 / 5251: train. loss = 0.0669Batch 1799 / 5251: train. loss = 0.0669Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0670Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 36 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0039, time = 33.846623 s
Batch 99 / 5251: train. loss = 0.0676Batch 199 / 5251: train. loss = 0.0675Batch 299 / 5251: train. loss = 0.0672Batch 399 / 5251: train. loss = 0.0672Batch 499 / 5251: train. loss = 0.0671Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0670Batch 799 / 5251: train. loss = 0.0671Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0670Batch 1099 / 5251: train. loss = 0.0671Batch 1199 / 5251: train. loss = 0.0671Batch 1299 / 5251: train. loss = 0.0671Batch 1399 / 5251: train. loss = 0.0671Batch 1499 / 5251: train. loss = 0.0671Batch 1599 / 5251: train. loss = 0.0671Batch 1699 / 5251: train. loss = 0.0670Batch 1799 / 5251: train. loss = 0.0670Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0669Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0669Batch 3099 / 5251: train. loss = 0.0669Batch 3199 / 5251: train. loss = 0.0669Batch 3299 / 5251: train. loss = 0.0669Batch 3399 / 5251: train. loss = 0.0669Batch 3499 / 5251: train. loss = 0.0669Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0670Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 37 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0025, time = 33.796935 s
Batch 99 / 5251: train. loss = 0.0670Batch 199 / 5251: train. loss = 0.0669Batch 299 / 5251: train. loss = 0.0670Batch 399 / 5251: train. loss = 0.0670Batch 499 / 5251: train. loss = 0.0670Batch 599 / 5251: train. loss = 0.0670Batch 699 / 5251: train. loss = 0.0669Batch 799 / 5251: train. loss = 0.0669Batch 899 / 5251: train. loss = 0.0669Batch 999 / 5251: train. loss = 0.0669Batch 1099 / 5251: train. loss = 0.0669Batch 1199 / 5251: train. loss = 0.0669Batch 1299 / 5251: train. loss = 0.0669Batch 1399 / 5251: train. loss = 0.0669Batch 1499 / 5251: train. loss = 0.0669Batch 1599 / 5251: train. loss = 0.0669Batch 1699 / 5251: train. loss = 0.0670Batch 1799 / 5251: train. loss = 0.0670Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0671Batch 2099 / 5251: train. loss = 0.0671Batch 2199 / 5251: train. loss = 0.0671Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0670Batch 2999 / 5251: train. loss = 0.0670Batch 3099 / 5251: train. loss = 0.0670Batch 3199 / 5251: train. loss = 0.0670Batch 3299 / 5251: train. loss = 0.0670Batch 3399 / 5251: train. loss = 0.0670Batch 3499 / 5251: train. loss = 0.0670Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0669Batch 3999 / 5251: train. loss = 0.0670Batch 4099 / 5251: train. loss = 0.0670Batch 4199 / 5251: train. loss = 0.0670Batch 4299 / 5251: train. loss = 0.0670Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 38 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0015, time = 33.766999 s
Batch 99 / 5251: train. loss = 0.0672Batch 199 / 5251: train. loss = 0.0671Batch 299 / 5251: train. loss = 0.0670Batch 399 / 5251: train. loss = 0.0671Batch 499 / 5251: train. loss = 0.0670Batch 599 / 5251: train. loss = 0.0671Batch 699 / 5251: train. loss = 0.0671Batch 799 / 5251: train. loss = 0.0671Batch 899 / 5251: train. loss = 0.0671Batch 999 / 5251: train. loss = 0.0671Batch 1099 / 5251: train. loss = 0.0670Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0670Batch 1399 / 5251: train. loss = 0.0670Batch 1499 / 5251: train. loss = 0.0669Batch 1599 / 5251: train. loss = 0.0669Batch 1699 / 5251: train. loss = 0.0669Batch 1799 / 5251: train. loss = 0.0669Batch 1899 / 5251: train. loss = 0.0669Batch 1999 / 5251: train. loss = 0.0669Batch 2099 / 5251: train. loss = 0.0669Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0670Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0669Batch 2999 / 5251: train. loss = 0.0669Batch 3099 / 5251: train. loss = 0.0669Batch 3199 / 5251: train. loss = 0.0669Batch 3299 / 5251: train. loss = 0.0669Batch 3399 / 5251: train. loss = 0.0669Batch 3499 / 5251: train. loss = 0.0669Batch 3599 / 5251: train. loss = 0.0669Batch 3699 / 5251: train. loss = 0.0669Batch 3799 / 5251: train. loss = 0.0669Batch 3899 / 5251: train. loss = 0.0669Batch 3999 / 5251: train. loss = 0.0669Batch 4099 / 5251: train. loss = 0.0669Batch 4199 / 5251: train. loss = 0.0669Batch 4299 / 5251: train. loss = 0.0669Batch 4399 / 5251: train. loss = 0.0669Batch 4499 / 5251: train. loss = 0.0669Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0669Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 39 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0007, time = 33.663131 s
Batch 99 / 5251: train. loss = 0.0672Batch 199 / 5251: train. loss = 0.0669Batch 299 / 5251: train. loss = 0.0667Batch 399 / 5251: train. loss = 0.0666Batch 499 / 5251: train. loss = 0.0669Batch 599 / 5251: train. loss = 0.0668Batch 699 / 5251: train. loss = 0.0669Batch 799 / 5251: train. loss = 0.0669Batch 899 / 5251: train. loss = 0.0670Batch 999 / 5251: train. loss = 0.0670Batch 1099 / 5251: train. loss = 0.0670Batch 1199 / 5251: train. loss = 0.0670Batch 1299 / 5251: train. loss = 0.0670Batch 1399 / 5251: train. loss = 0.0670Batch 1499 / 5251: train. loss = 0.0669Batch 1599 / 5251: train. loss = 0.0670Batch 1699 / 5251: train. loss = 0.0669Batch 1799 / 5251: train. loss = 0.0669Batch 1899 / 5251: train. loss = 0.0670Batch 1999 / 5251: train. loss = 0.0670Batch 2099 / 5251: train. loss = 0.0670Batch 2199 / 5251: train. loss = 0.0670Batch 2299 / 5251: train. loss = 0.0669Batch 2399 / 5251: train. loss = 0.0670Batch 2499 / 5251: train. loss = 0.0670Batch 2599 / 5251: train. loss = 0.0670Batch 2699 / 5251: train. loss = 0.0670Batch 2799 / 5251: train. loss = 0.0670Batch 2899 / 5251: train. loss = 0.0669Batch 2999 / 5251: train. loss = 0.0669Batch 3099 / 5251: train. loss = 0.0669Batch 3199 / 5251: train. loss = 0.0669Batch 3299 / 5251: train. loss = 0.0669Batch 3399 / 5251: train. loss = 0.0669Batch 3499 / 5251: train. loss = 0.0669Batch 3599 / 5251: train. loss = 0.0670Batch 3699 / 5251: train. loss = 0.0670Batch 3799 / 5251: train. loss = 0.0670Batch 3899 / 5251: train. loss = 0.0669Batch 3999 / 5251: train. loss = 0.0669Batch 4099 / 5251: train. loss = 0.0669Batch 4199 / 5251: train. loss = 0.0669Batch 4299 / 5251: train. loss = 0.0669Batch 4399 / 5251: train. loss = 0.0670Batch 4499 / 5251: train. loss = 0.0670Batch 4599 / 5251: train. loss = 0.0670Batch 4699 / 5251: train. loss = 0.0670Batch 4799 / 5251: train. loss = 0.0670Batch 4899 / 5251: train. loss = 0.0670Batch 4999 / 5251: train. loss = 0.0670Batch 5099 / 5251: train. loss = 0.0670Batch 5199 / 5251: train. loss = 0.0670Epoch 40 / 40: train. loss = 0.0670, val. loss = 0.0732, lr. = 0.0003, time = 33.865098 s
